\hypertarget{classstatement_1_1_statement___tokenizer}{}\doxysection{statement.\+Statement\+\_\+\+Tokenizer Class Reference}
\label{classstatement_1_1_statement___tokenizer}\index{statement.Statement\_Tokenizer@{statement.Statement\_Tokenizer}}


This is the base class of tokenization system.  


Inheritance diagram for statement.\+Statement\+\_\+\+Tokenizer\+:\begin{figure}[H]
\begin{center}
\leavevmode
\includegraphics[height=2.000000cm]{classstatement_1_1_statement___tokenizer}
\end{center}
\end{figure}
\doxysubsection*{Public Member Functions}
\begin{DoxyCompactItemize}
\item 
None \mbox{\hyperlink{classstatement_1_1_statement___tokenizer_a6448646d7a8eac6ecdcf864ffedbc45e}{\+\_\+\+\_\+init\+\_\+\+\_\+}} (self, str text)
\begin{DoxyCompactList}\small\item\em It abstracts the details of splitting the given text into tokens and let the client worry only about the results as she or he can get them though the statements property or words property. \end{DoxyCompactList}\item 
def \mbox{\hyperlink{classstatement_1_1_statement___tokenizer_a95805cd75ff6211b4ee440182f90a2d7}{statements}} (self)
\item 
\mbox{\Hypertarget{classstatement_1_1_statement___tokenizer_acd1864a3158a91d3ac21009aa3a8ca57}\label{classstatement_1_1_statement___tokenizer_acd1864a3158a91d3ac21009aa3a8ca57}} 
def {\bfseries words} (self)
\item 
\mbox{\Hypertarget{classstatement_1_1_statement___tokenizer_a46393ccff9b734f02abc536632515ffb}\label{classstatement_1_1_statement___tokenizer_a46393ccff9b734f02abc536632515ffb}} 
str {\bfseries \+\_\+\+\_\+str\+\_\+\+\_\+} (self)
\end{DoxyCompactItemize}


\doxysubsection{Detailed Description}
This is the base class of tokenization system. 

\doxysubsection{Constructor \& Destructor Documentation}
\mbox{\Hypertarget{classstatement_1_1_statement___tokenizer_a6448646d7a8eac6ecdcf864ffedbc45e}\label{classstatement_1_1_statement___tokenizer_a6448646d7a8eac6ecdcf864ffedbc45e}} 
\index{statement.Statement\_Tokenizer@{statement.Statement\_Tokenizer}!\_\_init\_\_@{\_\_init\_\_}}
\index{\_\_init\_\_@{\_\_init\_\_}!statement.Statement\_Tokenizer@{statement.Statement\_Tokenizer}}
\doxysubsubsection{\texorpdfstring{\_\_init\_\_()}{\_\_init\_\_()}}
{\footnotesize\ttfamily  None statement.\+Statement\+\_\+\+Tokenizer.\+\_\+\+\_\+init\+\_\+\+\_\+ (\begin{DoxyParamCaption}\item[{}]{self,  }\item[{str}]{text }\end{DoxyParamCaption})}



It abstracts the details of splitting the given text into tokens and let the client worry only about the results as she or he can get them though the statements property or words property. 


\begin{DoxyParams}{Parameters}
{\em str} & text \+: it is the gevin text on which the the class operates and yield the result to the client. \\
\hline
\end{DoxyParams}


Reimplemented in \mbox{\hyperlink{classtokenizer_1_1_q_tokenizer_a19214c752c986e339bc4d3afb6053c36}{tokenizer.\+QTokenizer}}.



\doxysubsection{Member Function Documentation}
\mbox{\Hypertarget{classstatement_1_1_statement___tokenizer_a95805cd75ff6211b4ee440182f90a2d7}\label{classstatement_1_1_statement___tokenizer_a95805cd75ff6211b4ee440182f90a2d7}} 
\index{statement.Statement\_Tokenizer@{statement.Statement\_Tokenizer}!statements@{statements}}
\index{statements@{statements}!statement.Statement\_Tokenizer@{statement.Statement\_Tokenizer}}
\doxysubsubsection{\texorpdfstring{statements()}{statements()}}
{\footnotesize\ttfamily def statement.\+Statement\+\_\+\+Tokenizer.\+statements (\begin{DoxyParamCaption}\item[{}]{self }\end{DoxyParamCaption})}

\begin{DoxyVerb}Returns a list of the statements derived from the inputed text.\end{DoxyVerb}
 

The documentation for this class was generated from the following file\+:\begin{DoxyCompactItemize}
\item 
statement.\+py\end{DoxyCompactItemize}
