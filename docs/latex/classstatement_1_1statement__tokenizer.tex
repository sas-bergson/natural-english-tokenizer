\hypertarget{classstatement_1_1statement__tokenizer}{}\doxysection{statement.\+statement\+\_\+tokenizer Class Reference}
\label{classstatement_1_1statement__tokenizer}\index{statement.statement\_tokenizer@{statement.statement\_tokenizer}}
\doxysubsection*{Public Member Functions}
\begin{DoxyCompactItemize}
\item 
def \mbox{\hyperlink{classstatement_1_1statement__tokenizer_a539e367f627418c7f0d210d6f1983f2b}{\+\_\+\+\_\+init\+\_\+\+\_\+}} (self)
\item 
list \mbox{\hyperlink{classstatement_1_1statement__tokenizer_ac4dcf1934e4320db5b0e359f03fcdac8}{get\+\_\+tokens}} (self)
\item 
def \mbox{\hyperlink{classstatement_1_1statement__tokenizer_a469ba550397d44ceed587fb37997979c}{list\+\_\+sentences}} (self)
\item 
def \mbox{\hyperlink{classstatement_1_1statement__tokenizer_a37903ce26416704ab5d8ba93efdc3e0a}{get\+\_\+sentence}} (self, text)
\item 
str \mbox{\hyperlink{classstatement_1_1statement__tokenizer_a9449283c6a72dff3aa0ede6aed4f0186}{\+\_\+\+\_\+str\+\_\+\+\_\+}} (self)
\item 
\mbox{\Hypertarget{classstatement_1_1statement__tokenizer_a14388c629e9253918bdf81efc19d157f}\label{classstatement_1_1statement__tokenizer_a14388c629e9253918bdf81efc19d157f}} 
def {\bfseries tokenize\+\_\+tokens} (self)
\end{DoxyCompactItemize}


\doxysubsection{Constructor \& Destructor Documentation}
\mbox{\Hypertarget{classstatement_1_1statement__tokenizer_a539e367f627418c7f0d210d6f1983f2b}\label{classstatement_1_1statement__tokenizer_a539e367f627418c7f0d210d6f1983f2b}} 
\index{statement.statement\_tokenizer@{statement.statement\_tokenizer}!\_\_init\_\_@{\_\_init\_\_}}
\index{\_\_init\_\_@{\_\_init\_\_}!statement.statement\_tokenizer@{statement.statement\_tokenizer}}
\doxysubsubsection{\texorpdfstring{\_\_init\_\_()}{\_\_init\_\_()}}
{\footnotesize\ttfamily def statement.\+statement\+\_\+tokenizer.\+\_\+\+\_\+init\+\_\+\+\_\+ (\begin{DoxyParamCaption}\item[{}]{self }\end{DoxyParamCaption})}

\begin{DoxyVerb}This method is the constructor. where all the regex are defined and the word that the user or the calling file will use to call the method.\end{DoxyVerb}
 

\doxysubsection{Member Function Documentation}
\mbox{\Hypertarget{classstatement_1_1statement__tokenizer_a9449283c6a72dff3aa0ede6aed4f0186}\label{classstatement_1_1statement__tokenizer_a9449283c6a72dff3aa0ede6aed4f0186}} 
\index{statement.statement\_tokenizer@{statement.statement\_tokenizer}!\_\_str\_\_@{\_\_str\_\_}}
\index{\_\_str\_\_@{\_\_str\_\_}!statement.statement\_tokenizer@{statement.statement\_tokenizer}}
\doxysubsubsection{\texorpdfstring{\_\_str\_\_()}{\_\_str\_\_()}}
{\footnotesize\ttfamily  str statement.\+statement\+\_\+tokenizer.\+\_\+\+\_\+str\+\_\+\+\_\+ (\begin{DoxyParamCaption}\item[{}]{self }\end{DoxyParamCaption})}

\begin{DoxyVerb}This method is responsible for the printing of the tokens that are returned by the get_tokens method.it takes no arguments and returns a string of the tokens.\end{DoxyVerb}
 \mbox{\Hypertarget{classstatement_1_1statement__tokenizer_a37903ce26416704ab5d8ba93efdc3e0a}\label{classstatement_1_1statement__tokenizer_a37903ce26416704ab5d8ba93efdc3e0a}} 
\index{statement.statement\_tokenizer@{statement.statement\_tokenizer}!get\_sentence@{get\_sentence}}
\index{get\_sentence@{get\_sentence}!statement.statement\_tokenizer@{statement.statement\_tokenizer}}
\doxysubsubsection{\texorpdfstring{get\_sentence()}{get\_sentence()}}
{\footnotesize\ttfamily def statement.\+statement\+\_\+tokenizer.\+get\+\_\+sentence (\begin{DoxyParamCaption}\item[{}]{self,  }\item[{}]{text }\end{DoxyParamCaption})}

\begin{DoxyVerb}"This method is responsible for splitting a text block in the the different sentennces composing it\end{DoxyVerb}
 \mbox{\Hypertarget{classstatement_1_1statement__tokenizer_ac4dcf1934e4320db5b0e359f03fcdac8}\label{classstatement_1_1statement__tokenizer_ac4dcf1934e4320db5b0e359f03fcdac8}} 
\index{statement.statement\_tokenizer@{statement.statement\_tokenizer}!get\_tokens@{get\_tokens}}
\index{get\_tokens@{get\_tokens}!statement.statement\_tokenizer@{statement.statement\_tokenizer}}
\doxysubsubsection{\texorpdfstring{get\_tokens()}{get\_tokens()}}
{\footnotesize\ttfamily  list statement.\+statement\+\_\+tokenizer.\+get\+\_\+tokens (\begin{DoxyParamCaption}\item[{}]{self }\end{DoxyParamCaption})}

\begin{DoxyVerb}This method is responsible for the splitting of the individual strings into the required tokens which takes text the text that is to be split into tokens. and returns a list of tokens.\end{DoxyVerb}
 \mbox{\Hypertarget{classstatement_1_1statement__tokenizer_a469ba550397d44ceed587fb37997979c}\label{classstatement_1_1statement__tokenizer_a469ba550397d44ceed587fb37997979c}} 
\index{statement.statement\_tokenizer@{statement.statement\_tokenizer}!list\_sentences@{list\_sentences}}
\index{list\_sentences@{list\_sentences}!statement.statement\_tokenizer@{statement.statement\_tokenizer}}
\doxysubsubsection{\texorpdfstring{list\_sentences()}{list\_sentences()}}
{\footnotesize\ttfamily def statement.\+statement\+\_\+tokenizer.\+list\+\_\+sentences (\begin{DoxyParamCaption}\item[{}]{self }\end{DoxyParamCaption})}

\begin{DoxyVerb}"This method is responsible for printing the different sentences present in the text\end{DoxyVerb}
 

The documentation for this class was generated from the following file\+:\begin{DoxyCompactItemize}
\item 
statement.\+py\end{DoxyCompactItemize}
