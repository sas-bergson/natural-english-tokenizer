var searchData=
[
  ['natural_2denglish_2dtokenizer_0',['natural-english-tokenizer',['../md__r_e_a_d_m_e.html',1,'']]],
  ['noun_1',['noun',['../namespacelexical.html#a8fe4e5fa0f02ae8f8f5b3eb2f46fd25e',1,'lexical']]],
  ['nounlist_2',['nounList',['../classmain_1_1statement__tokenizer.html#a5c645ea998ef0569b7e292e4be29cc60',1,'main::statement_tokenizer']]],
  ['nouns_3',['nouns',['../namespaceparts__speech.html#acdadfc9b9cbef9805ef5ab3c064c51b3',1,'parts_speech']]]
];
