{\rtf1\ansi\ansicpg1252\uc1 \deff0\deflang1033\deflangfe1033
{\fonttbl {\f0\froman\fcharset0\fprq2{\*\panose 02020603050405020304}Times New Roman;}
{\f1\fswiss\fcharset0\fprq2{\*\panose 020b0604020202020204}Arial;}
{\f2\fmodern\fcharset0\fprq1{\*\panose 02070309020205020404}Courier New;}
{\f3\froman\fcharset2\fprq2{\*\panose 05050102010706020507}Symbol;}
}
{\colortbl;\red0\green0\blue0;\red0\green0\blue255;\red0\green255\blue255;\red0\green255\blue0;\red255\green0\blue255;\red255\green0\blue0;\red255\green255\blue0;\red255\green255\blue255;\red0\green0\blue128;\red0\green128\blue128;\red0\green128\blue0;\red128\green0\blue128;\red128\green0\blue0;\red128\green128\blue0;\red128\green128\blue128;\red192\green192\blue192;\red0\green128\blue0;\red96\green64\blue32;\rede0\green128\blue0;\red128\green0\blue0;\red128\green96\blue32;\red0\green32\blue128;\red0\green128\blue128;\red255\green0\blue255;\red0\green0\blue0;\red112\green0\blue112;\red255\green0\blue0;}
{\stylesheet
{\widctlpar\adjustright \fs20\cgrid \snext0 Normal;}
{\paperw11900\paperh16840\margl1800\margr1800\margt1440\margb1440\gutter0\ltrsect}
{\s1\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs36\kerning36\cgrid \sbasedon0 \snext0 heading 1;}
{\s2\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs28\kerning28\cgrid \sbasedon0 \snext0 heading 2;}
{\s3\sb240\sa60\keepn\widctlpar\adjustright \b\f1\cgrid \sbasedon0 \snext0 heading 3;}
{\s4\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs20\cgrid \sbasedon0 \snext0 heading 4;}{\*\cs10 \additive Default Paragraph Font;}
{\s5\sb90\sa30\keepn\widctlpar\adjustright \b\f1\fs20\cgrid \sbasedon0 \snext0 heading 5;}{\*\cs10 \additive Default Paragraph Font;}
{\s15\qc\sb240\sa60\widctlpar\outlinelevel0\adjustright \b\f1\fs32\kerning28\cgrid \sbasedon0 \snext15 Title;}
{\s16\qc\sa60\widctlpar\outlinelevel1\adjustright \f1\cgrid \sbasedon0 \snext16 Subtitle;}
{\s17\sa60\sb30\widctlpar\qj \fs22\cgrid \sbasedon0 \snext17 BodyText;}
{\s18\widctlpar\fs22\cgrid \sbasedon0 \snext18 DenseText;}
{\s28\widctlpar\tqc\tx4320\tqr\tx8640\adjustright \fs20\cgrid \sbasedon0 \snext28 header;}
{\s29\widctlpar\tqc\tx4320\tqr\tx8640\qr\adjustright \fs20\cgrid \sbasedon0 \snext29 footer;}
{\s30\li360\sa60\sb120\keepn\widctlpar\adjustright \b\f1\fs20\cgrid \sbasedon0 \snext30 GroupHeader;}
{\s40\li0\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid \sbasedon0 \snext41 Code Example 0;}
{\s41\li360\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid \sbasedon0 \snext42 Code Example 1;}
{\s42\li720\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid \sbasedon0 \snext43 Code Example 2;}
{\s43\li1080\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid \sbasedon0 \snext44 Code Example 3;}
{\s44\li1440\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid \sbasedon0 \snext45 Code Example 4;}
{\s45\li1800\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid \sbasedon0 \snext46 Code Example 5;}
{\s46\li2160\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid \sbasedon0 \snext47 Code Example 6;}
{\s47\li2520\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid \sbasedon0 \snext48 Code Example 7;}
{\s48\li2880\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid \sbasedon0 \snext49 Code Example 8;}
{\s49\li3240\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid \sbasedon0 \snext50 Code Example 9;}
{\s50\li3600\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid \sbasedon0 \snext51 Code Example 10;}
{\s51\li3960\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid \sbasedon0 \snext52 Code Example 11;}
{\s52\li4320\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid \sbasedon0 \snext53 Code Example 12;}
{\s53\li4680\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid \sbasedon0 \snext53 Code Example 13;}
{\s60\li0\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid \sbasedon0 \snext61 List Continue 0;}
{\s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid \sbasedon0 \snext62 List Continue 1;}
{\s62\li720\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid \sbasedon0 \snext63 List Continue 2;}
{\s63\li1080\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid \sbasedon0 \snext64 List Continue 3;}
{\s64\li1440\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid \sbasedon0 \snext65 List Continue 4;}
{\s65\li1800\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid \sbasedon0 \snext66 List Continue 5;}
{\s66\li2160\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid \sbasedon0 \snext67 List Continue 6;}
{\s67\li2520\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid \sbasedon0 \snext68 List Continue 7;}
{\s68\li2880\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid \sbasedon0 \snext69 List Continue 8;}
{\s69\li3240\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid \sbasedon0 \snext70 List Continue 9;}
{\s70\li3600\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid \sbasedon0 \snext71 List Continue 10;}
{\s71\li3960\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid \sbasedon0 \snext72 List Continue 11;}
{\s72\li4320\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid \sbasedon0 \snext73 List Continue 12;}
{\s73\li4680\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid \sbasedon0 \snext73 List Continue 13;}
{\s80\li0\widctlpar\ql\adjustright \fs20\cgrid \sbasedon0 \snext81 DescContinue 0;}
{\s81\li360\widctlpar\ql\adjustright \fs20\cgrid \sbasedon0 \snext82 DescContinue 1;}
{\s82\li720\widctlpar\ql\adjustright \fs20\cgrid \sbasedon0 \snext83 DescContinue 2;}
{\s83\li1080\widctlpar\ql\adjustright \fs20\cgrid \sbasedon0 \snext84 DescContinue 3;}
{\s84\li1440\widctlpar\ql\adjustright \fs20\cgrid \sbasedon0 \snext85 DescContinue 4;}
{\s85\li1800\widctlpar\ql\adjustright \fs20\cgrid \sbasedon0 \snext86 DescContinue 5;}
{\s86\li2160\widctlpar\ql\adjustright \fs20\cgrid \sbasedon0 \snext87 DescContinue 6;}
{\s87\li2520\widctlpar\ql\adjustright \fs20\cgrid \sbasedon0 \snext88 DescContinue 7;}
{\s88\li2880\widctlpar\ql\adjustright \fs20\cgrid \sbasedon0 \snext89 DescContinue 8;}
{\s89\li3240\widctlpar\ql\adjustright \fs20\cgrid \sbasedon0 \snext90 DescContinue 9;}
{\s90\li3600\widctlpar\ql\adjustright \fs20\cgrid \sbasedon0 \snext91 DescContinue 10;}
{\s91\li3960\widctlpar\ql\adjustright \fs20\cgrid \sbasedon0 \snext92 DescContinue 11;}
{\s92\li4320\widctlpar\ql\adjustright \fs20\cgrid \sbasedon0 \snext93 DescContinue 12;}
{\s93\li4680\widctlpar\ql\adjustright \fs20\cgrid \sbasedon0 \snext93 DescContinue 13;}
{\s100\li0\sa30\sb30\widctlpar\tqr\tldot\tx8640\adjustright \fs20\cgrid \sbasedon0 \snext101 LatexTOC 0;}
{\s101\li360\sa27\sb27\widctlpar\tqr\tldot\tx8640\adjustright \fs20\cgrid \sbasedon0 \snext102 LatexTOC 1;}
{\s102\li720\sa24\sb24\widctlpar\tqr\tldot\tx8640\adjustright \fs20\cgrid \sbasedon0 \snext103 LatexTOC 2;}
{\s103\li1080\sa21\sb21\widctlpar\tqr\tldot\tx8640\adjustright \fs20\cgrid \sbasedon0 \snext104 LatexTOC 3;}
{\s104\li1440\sa18\sb18\widctlpar\tqr\tldot\tx8640\adjustright \fs20\cgrid \sbasedon0 \snext105 LatexTOC 4;}
{\s105\li1800\sa15\sb15\widctlpar\tqr\tldot\tx8640\adjustright \fs20\cgrid \sbasedon0 \snext106 LatexTOC 5;}
{\s106\li2160\sa12\sb12\widctlpar\tqr\tldot\tx8640\adjustright \fs20\cgrid \sbasedon0 \snext107 LatexTOC 6;}
{\s107\li2520\sa9\sb9\widctlpar\tqr\tldot\tx8640\adjustright \fs20\cgrid \sbasedon0 \snext108 LatexTOC 7;}
{\s108\li2880\sa6\sb6\widctlpar\tqr\tldot\tx8640\adjustright \fs20\cgrid \sbasedon0 \snext109 LatexTOC 8;}
{\s109\li3240\sa3\sb3\widctlpar\tqr\tldot\tx8640\adjustright \fs20\cgrid \sbasedon0 \snext110 LatexTOC 9;}
{\s110\li3600\sa3\sb3\widctlpar\tqr\tldot\tx8640\adjustright \fs20\cgrid \sbasedon0 \snext111 LatexTOC 10;}
{\s111\li3960\sa3\sb3\widctlpar\tqr\tldot\tx8640\adjustright \fs20\cgrid \sbasedon0 \snext112 LatexTOC 11;}
{\s112\li4320\sa3\sb3\widctlpar\tqr\tldot\tx8640\adjustright \fs20\cgrid \sbasedon0 \snext113 LatexTOC 12;}
{\s113\li4680\sa3\sb3\widctlpar\tqr\tldot\tx8640\adjustright \fs20\cgrid \sbasedon0 \snext113 LatexTOC 13;}
{\s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid \sbasedon0 \snext121 \sautoupd List Bullet 0;}
{\s121\fi-360\li720\widctlpar\jclisttab\tx720{\*\pn \pnlvlbody\ilvl0\ls2\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid \sbasedon0 \snext122 \sautoupd List Bullet 1;}
{\s122\fi-360\li1080\widctlpar\jclisttab\tx1080{\*\pn \pnlvlbody\ilvl0\ls3\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid \sbasedon0 \snext123 \sautoupd List Bullet 2;}
{\s123\fi-360\li1440\widctlpar\jclisttab\tx1440{\*\pn \pnlvlbody\ilvl0\ls4\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid \sbasedon0 \snext124 \sautoupd List Bullet 3;}
{\s124\fi-360\li1800\widctlpar\jclisttab\tx1800{\*\pn \pnlvlbody\ilvl0\ls5\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid \sbasedon0 \snext125 \sautoupd List Bullet 4;}
{\s125\fi-360\li2160\widctlpar\jclisttab\tx2160{\*\pn \pnlvlbody\ilvl0\ls6\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid \sbasedon0 \snext126 \sautoupd List Bullet 5;}
{\s126\fi-360\li2520\widctlpar\jclisttab\tx2520{\*\pn \pnlvlbody\ilvl0\ls7\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid \sbasedon0 \snext127 \sautoupd List Bullet 6;}
{\s127\fi-360\li2880\widctlpar\jclisttab\tx2880{\*\pn \pnlvlbody\ilvl0\ls8\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid \sbasedon0 \snext128 \sautoupd List Bullet 7;}
{\s128\fi-360\li3240\widctlpar\jclisttab\tx3240{\*\pn \pnlvlbody\ilvl0\ls9\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid \sbasedon0 \snext129 \sautoupd List Bullet 8;}
{\s129\fi-360\li3600\widctlpar\jclisttab\tx3600{\*\pn \pnlvlbody\ilvl0\ls10\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid \sbasedon0 \snext130 \sautoupd List Bullet 9;}
{\s130\fi-360\li3960\widctlpar\jclisttab\tx3960{\*\pn \pnlvlbody\ilvl0\ls11\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid \sbasedon0 \snext131 \sautoupd List Bullet 10;}
{\s131\fi-360\li4320\widctlpar\jclisttab\tx4320{\*\pn \pnlvlbody\ilvl0\ls12\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid \sbasedon0 \snext132 \sautoupd List Bullet 11;}
{\s132\fi-360\li4680\widctlpar\jclisttab\tx4680{\*\pn \pnlvlbody\ilvl0\ls13\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid \sbasedon0 \snext133 \sautoupd List Bullet 12;}
{\s133\fi-360\li5040\widctlpar\jclisttab\tx5040{\*\pn \pnlvlbody\ilvl0\ls14\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid \sbasedon0 \snext133 \sautoupd List Bullet 13;}
{\s140\fi-360\li360\widctlpar\fs20\cgrid \sbasedon0 \snext141 \sautoupd List Enum 0;}
{\s141\fi-360\li720\widctlpar\fs20\cgrid \sbasedon0 \snext142 \sautoupd List Enum 1;}
{\s142\fi-360\li1080\widctlpar\fs20\cgrid \sbasedon0 \snext143 \sautoupd List Enum 2;}
{\s143\fi-360\li1440\widctlpar\fs20\cgrid \sbasedon0 \snext144 \sautoupd List Enum 3;}
{\s144\fi-360\li1800\widctlpar\fs20\cgrid \sbasedon0 \snext145 \sautoupd List Enum 4;}
{\s145\fi-360\li2160\widctlpar\fs20\cgrid \sbasedon0 \snext146 \sautoupd List Enum 5;}
{\s146\fi-360\li2520\widctlpar\fs20\cgrid \sbasedon0 \snext147 \sautoupd List Enum 6;}
{\s147\fi-360\li2880\widctlpar\fs20\cgrid \sbasedon0 \snext148 \sautoupd List Enum 7;}
{\s148\fi-360\li3240\widctlpar\fs20\cgrid \sbasedon0 \snext149 \sautoupd List Enum 8;}
{\s149\fi-360\li3600\widctlpar\fs20\cgrid \sbasedon0 \snext150 \sautoupd List Enum 9;}
{\s150\fi-360\li3960\widctlpar\fs20\cgrid \sbasedon0 \snext151 \sautoupd List Enum 10;}
{\s151\fi-360\li4320\widctlpar\fs20\cgrid \sbasedon0 \snext152 \sautoupd List Enum 11;}
{\s152\fi-360\li4680\widctlpar\fs20\cgrid \sbasedon0 \snext153 \sautoupd List Enum 12;}
{\s153\fi-360\li5040\widctlpar\fs20\cgrid \sbasedon0 \snext153 \sautoupd List Enum 13;}
}
{\info 
{\title {\comment natural english language tokenizer }natural english language tokenizer}
{\comment Generated by doxygen 1.9.5.}
{\creatim \yr2022\mo12\dy12\hr14\min48\sec58}
}\pard\plain 
\sectd\pgnlcrm
{\footer \s29\widctlpar\tqc\tx4320\tqr\tx8640\qr\adjustright \fs20\cgrid {\chpgn}}
\pard\plain \s16\qc\sa60\widctlpar\outlinelevel1\adjustright \f1\cgrid 
\vertalc\qc\par\par\par\par\par\par\par
\pard\plain \s15\qc\sb240\sa60\widctlpar\outlinelevel0\adjustright \b\f1\fs32\kerning28\cgrid 
{\field\fldedit {\*\fldinst TITLE \\*MERGEFORMAT}{\fldrslt natural english language tokenizer}}\par
\pard\plain \s16\qc\sa60\widctlpar\outlinelevel1\adjustright \f1\cgrid 
\par
\par\par\par\par\par\par\par\par\par\par\par\par
\pard\plain \s16\qc\sa60\widctlpar\outlinelevel1\adjustright \f1\cgrid 
{\field\fldedit {\*\fldinst AUTHOR \\*MERGEFORMAT}{\fldrslt AUTHOR}}\par
Version \par{\field\fldedit {\*\fldinst CREATEDATE \\*MERGEFORMAT}{\fldrslt Mon Dec 12 2022 }}\par
\page\page\vertalt
\pard\plain 
\s1\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs36\kerning36\cgrid Table of Contents\par
\pard\plain \par
{\field\fldedit {\*\fldinst TOC \\f \\*MERGEFORMAT}{\fldrslt Table of contents}}\par
\pard\plain 
\sect \sbkpage \pgndec \pgnrestart
\sect \sectd \sbknone
{\footer \s29\widctlpar\tqc\tx4320\tqr\tx8640\qr\adjustright \fs20\cgrid {\chpgn}}

\pard\plain \sect\sbkpage
\s1\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs36\kerning36\cgrid 
natural-english-tokenizer{\tc \v natural-english-tokenizer}\par \pard\plain 
{\bkmkstart AAAAAAAACO}
{\bkmkend AAAAAAAACO}
\par \pard\plain 
{
\pard\plain \s17\sa60\sb30\widctlpar\qj \fs22\cgrid {\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
gfghkjkk \par
}}

\pard\plain \sect\sbkpage
\s1\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs36\kerning36\cgrid 
Namespace Index\par \pard\plain 
{\tc \v Namespace Index}
\pard\plain \s2\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs28\kerning28\cgrid 
Namespace List\par \pard\plain 
{
\pard\plain \s17\sa60\sb30\widctlpar\qj \fs22\cgrid Here is a list of all namespaces with brief descriptions:}
{
\par
\pard\plain \s101\li360\sa27\sb27\widctlpar\tqr\tldot\tx8640\adjustright \fs20\cgrid 
{\b {\b lexical} } \tab {\field\fldedit {\*\fldinst PAGEREF AAAAAAAAAJ \\*MERGEFORMAT}{\fldrslt pagenum}}
\par
{\b {\b main} } \tab {\field\fldedit {\*\fldinst PAGEREF AAAAAAAABA \\*MERGEFORMAT}{\fldrslt pagenum}}
\par
{\b {\b parts_speech} } \tab {\field\fldedit {\*\fldinst PAGEREF AAAAAAAABU \\*MERGEFORMAT}{\fldrslt pagenum}}
\par
{\b {\b statement} } \tab {\field\fldedit {\*\fldinst PAGEREF AAAAAAAACC \\*MERGEFORMAT}{\fldrslt pagenum}}
\par
\par}
\pard\plain \sect\sbkpage
\s1\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs36\kerning36\cgrid 
Class Index\par \pard\plain 
{\tc \v Class Index}
\pard\plain \s2\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs28\kerning28\cgrid 
Class List\par \pard\plain 
{
\pard\plain \s17\sa60\sb30\widctlpar\qj \fs22\cgrid Here are the classes, structs, unions and interfaces with brief descriptions:}
{
\par
\pard\plain \s101\li360\sa27\sb27\widctlpar\tqr\tldot\tx8640\adjustright \fs20\cgrid 
{\b {\b main.statement_tokenizer} } \tab {\field\fldedit {\*\fldinst PAGEREF AAAAAAAABB \\*MERGEFORMAT}{\fldrslt pagenum}}
\par
{\b {\b statement.statement_tokenizer} } \tab {\field\fldedit {\*\fldinst PAGEREF AAAAAAAACD \\*MERGEFORMAT}{\fldrslt pagenum}}
\par
\par}
\pard\plain \sect\sbkpage
\s1\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs36\kerning36\cgrid 
File Index\par \pard\plain 
{\tc \v File Index}
\pard\plain \s2\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs28\kerning28\cgrid 
File List\par \pard\plain 
{
\pard\plain \s17\sa60\sb30\widctlpar\qj \fs22\cgrid Here is a list of all files with brief descriptions:}
{
\par
\pard\plain \s101\li360\sa27\sb27\widctlpar\tqr\tldot\tx8640\adjustright \fs20\cgrid 
{\b {\b lexical.py} } \tab {\field\fldedit {\*\fldinst PAGEREF AAAAAAAAAE \\*MERGEFORMAT}{\fldrslt pagenum}}
\par
{\b {\b main.py} } \tab {\field\fldedit {\*\fldinst PAGEREF AAAAAAAAAF \\*MERGEFORMAT}{\fldrslt pagenum}}
\par
{\b {\b parts_speech.py} } \tab {\field\fldedit {\*\fldinst PAGEREF AAAAAAAAAG \\*MERGEFORMAT}{\fldrslt pagenum}}
\par
{\b {\b statement.py} } \tab {\field\fldedit {\*\fldinst PAGEREF AAAAAAAAAI \\*MERGEFORMAT}{\fldrslt pagenum}}
\par
\par}
\pard\plain \sect\sbkpage
\s1\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs36\kerning36\cgrid 
Namespace Documentation\par \pard\plain 
\pard\plain \s2\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs28\kerning28\cgrid 
lexical Namespace Reference\par \pard\plain 
{\tc\tcl2 \v lexical}
{\xe \v lexical}
{\bkmkstart AAAAAAAAAJ}
{\bkmkend AAAAAAAAAJ}
\pard\plain \s3\sb240\sa60\keepn\widctlpar\adjustright \b\f1\cgrid 
Variables\par
\pard\plain 

{
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
string {\b text} = "Its show time"\par
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
list {\b punctuation} = ['!', '?',',','.',';',':']\par
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
list {\b noun} = ['+', '-', '*', '/', '=', '+=', '-=', '==', '<', '>', '<=', '>=']\par
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
list {\b adverb}\par
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
list {\b verb}\par
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
list {\b in_adverb} = []\par
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
list {\b in_spl_punctuation} = []\par
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
list {\b in_noun} = []\par
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
list {\b in_verb} = []\par
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
list {\b in_identifiers} = []\par
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
list {\b in_constants} = []\par
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
list {\b tokens} = []\par
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
bool {\b isStr} = False\par
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
bool {\b isWord} = False\par
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
int {\b isCmt} = 0\par
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
string {\b token} = ''\par
}
{\pard\widctlpar\brdrb\brdrs\brdrw5\brsp20 \adjustright \par}
\pard\plain \s3\sb240\sa60\keepn\widctlpar\adjustright \b\f1\cgrid 
Variable Documentation\par
\pard\plain 
{\xe \v adverb\:lexical}
{\xe \v lexical\:adverb}
\pard\plain \s4\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs20\cgrid {
{\b 
list lexical.adverb}}
\par
{\bkmkstart AAAAAAAAAK}
{\bkmkend AAAAAAAAAK}
{
\pard\plain \s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid 
{\b Initial value:}{
\pard\plain \s41\li360\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid 00001 =  [{\cf22 'auto'},{\cf22 'break'}, {\cf22 'case'}, {\cf22 'char'}, {\cf22 'const'}, {\cf22 'continue'}, {\cf22 'default'}, {\cf22 'do'}, \par
00002             {\cf22 'double'}, {\cf22 'else'}, {\cf22 'enum'}, {\cf22 'extern'}, {\cf22 'float'}, {\cf22 'for'}, {\cf22 'goto'}, {\cf22 'if'}, \par
00003             {\cf22 'int'}, {\cf22 'long'}, {\cf22 'register'}, {\cf22 'return'}, {\cf22 'short'}, {\cf22 'signed'}, {\cf22 'sizeof'}, {\cf22 'static'}, \par
00004             {\cf22 'struct'}, {\cf22 'switch'}, {\cf22 'typedef'}, {\cf22 'union'}, {\cf22 'unsigned'}, {\cf22 'void'}, {\cf22 'volatile'}, {\cf22 'while'}]\par
}
{
Definition at line {\b 9} of file {\b lexical.py}.}\par
}
{\xe \v in_adverb\:lexical}
{\xe \v lexical\:in_adverb}
\pard\plain \s4\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs20\cgrid {
{\b 
list lexical.in_adverb = []}}
\par
{\bkmkstart AAAAAAAAAL}
{\bkmkend AAAAAAAAAL}
{
\pard\plain \s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid 
\par
{
Definition at line {\b 19} of file {\b lexical.py}.}\par
}
{\xe \v in_constants\:lexical}
{\xe \v lexical\:in_constants}
\pard\plain \s4\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs20\cgrid {
{\b 
list lexical.in_constants = []}}
\par
{\bkmkstart AAAAAAAAAM}
{\bkmkend AAAAAAAAAM}
{
\pard\plain \s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid 
\par
{
Definition at line {\b 24} of file {\b lexical.py}.}\par
}
{\xe \v in_identifiers\:lexical}
{\xe \v lexical\:in_identifiers}
\pard\plain \s4\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs20\cgrid {
{\b 
list lexical.in_identifiers = []}}
\par
{\bkmkstart AAAAAAAAAN}
{\bkmkend AAAAAAAAAN}
{
\pard\plain \s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid 
\par
{
Definition at line {\b 23} of file {\b lexical.py}.}\par
}
{\xe \v in_noun\:lexical}
{\xe \v lexical\:in_noun}
\pard\plain \s4\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs20\cgrid {
{\b 
list lexical.in_noun = []}}
\par
{\bkmkstart AAAAAAAAAO}
{\bkmkend AAAAAAAAAO}
{
\pard\plain \s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid 
\par
{
Definition at line {\b 21} of file {\b lexical.py}.}\par
}
{\xe \v in_spl_punctuation\:lexical}
{\xe \v lexical\:in_spl_punctuation}
\pard\plain \s4\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs20\cgrid {
{\b 
list lexical.in_spl_punctuation = []}}
\par
{\bkmkstart AAAAAAAAAP}
{\bkmkend AAAAAAAAAP}
{
\pard\plain \s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid 
\par
{
Definition at line {\b 20} of file {\b lexical.py}.}\par
}
{\xe \v in_verb\:lexical}
{\xe \v lexical\:in_verb}
\pard\plain \s4\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs20\cgrid {
{\b 
list lexical.in_verb = []}}
\par
{\bkmkstart AAAAAAAAAQ}
{\bkmkend AAAAAAAAAQ}
{
\pard\plain \s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid 
\par
{
Definition at line {\b 22} of file {\b lexical.py}.}\par
}
{\xe \v isCmt\:lexical}
{\xe \v lexical\:isCmt}
\pard\plain \s4\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs20\cgrid {
{\b 
int lexical.isCmt = 0}}
\par
{\bkmkstart AAAAAAAAAR}
{\bkmkend AAAAAAAAAR}
{
\pard\plain \s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid 
\par
{
Definition at line {\b 29} of file {\b lexical.py}.}\par
}
{\xe \v isStr\:lexical}
{\xe \v lexical\:isStr}
\pard\plain \s4\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs20\cgrid {
{\b 
bool lexical.isStr = False}}
\par
{\bkmkstart AAAAAAAAAS}
{\bkmkend AAAAAAAAAS}
{
\pard\plain \s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid 
\par
{
Definition at line {\b 27} of file {\b lexical.py}.}\par
}
{\xe \v isWord\:lexical}
{\xe \v lexical\:isWord}
\pard\plain \s4\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs20\cgrid {
{\b 
bool lexical.isWord = False}}
\par
{\bkmkstart AAAAAAAAAT}
{\bkmkend AAAAAAAAAT}
{
\pard\plain \s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid 
\par
{
Definition at line {\b 28} of file {\b lexical.py}.}\par
}
{\xe \v noun\:lexical}
{\xe \v lexical\:noun}
\pard\plain \s4\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs20\cgrid {
{\b 
list lexical.noun = ['+', '-', '*', '/', '=', '+=', '-=', '==', '<', '>', '<=', '>=']}}
\par
{\bkmkstart AAAAAAAAAU}
{\bkmkend AAAAAAAAAU}
{
\pard\plain \s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid 
\par
{
Definition at line {\b 8} of file {\b lexical.py}.}\par
}
{\xe \v punctuation\:lexical}
{\xe \v lexical\:punctuation}
\pard\plain \s4\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs20\cgrid {
{\b 
list lexical.punctuation = ['!', '?',',','.',';',':']}}
\par
{\bkmkstart AAAAAAAAAV}
{\bkmkend AAAAAAAAAV}
{
\pard\plain \s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid 
\par
{
Definition at line {\b 7} of file {\b lexical.py}.}\par
}
{\xe \v text\:lexical}
{\xe \v lexical\:text}
\pard\plain \s4\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs20\cgrid {
{\b 
string lexical.text = "Its show time"}}
\par
{\bkmkstart AAAAAAAAAW}
{\bkmkend AAAAAAAAAW}
{
\pard\plain \s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid 
\par
{
Definition at line {\b 5} of file {\b lexical.py}.}\par
}
{\xe \v token\:lexical}
{\xe \v lexical\:token}
\pard\plain \s4\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs20\cgrid {
{\b 
string lexical.token = ''}}
\par
{\bkmkstart AAAAAAAAAX}
{\bkmkend AAAAAAAAAX}
{
\pard\plain \s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid 
\par
{
Definition at line {\b 30} of file {\b lexical.py}.}\par
}
{\xe \v tokens\:lexical}
{\xe \v lexical\:tokens}
\pard\plain \s4\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs20\cgrid {
{\b 
list lexical.tokens = []}}
\par
{\bkmkstart AAAAAAAAAY}
{\bkmkend AAAAAAAAAY}
{
\pard\plain \s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid 
\par
{
Definition at line {\b 26} of file {\b lexical.py}.}\par
}
{\xe \v verb\:lexical}
{\xe \v lexical\:verb}
\pard\plain \s4\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs20\cgrid {
{\b 
list lexical.verb}}
\par
{\bkmkstart AAAAAAAAAZ}
{\bkmkend AAAAAAAAAZ}
{
\pard\plain \s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid 
{\b Initial value:}{
\pard\plain \s41\li360\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid 00001 =  [ {\cf22 'gag'} , {\cf22 'gain'} , {\cf22 'gallop'}, {\cf22 'gamble'} ,{\cf22 'gargle'} ,{\cf22 'garnish'} ,{\cf22 'gasp'} ,{\cf22 'gather'},{\cf22 'gauge'} ,{\cf22 'geld'} ,{\cf22 'generalize'} ,{\cf22 'generate'} , {\cf22 'germinate'} , {\cf22 'gesticulate'}, \par
00002  {\cf22 'get'} , {\cf22 'giggle'}, {\cf22 'gild'} ,{\cf22 'give'}, {\cf22 'glance'}, {\cf22 'glaze'} ,{\cf22 'gleam'} ,{\cf22 'glean'} ,{\cf22 'glide'} ,{\cf22 'glimmer'}, {\cf22 'glimpse'} ,{\cf22 'glisten'} ,{\cf22 'glitter'} ,{\cf22 'glorify'}, {\cf22 'gloss'} ,{\cf22 'glow'} ,{\cf22 'glue'} ,{\cf22 'gnash'} ,{\cf22 'gnaw'} ,{\cf22 'go'} ,{\cf22 'goad'}, {\cf22 'gossip'},  {\cf22 'govern'} ,{\cf22 'grab'} , {\cf22 'grace'} ,{\cf22 'grade'} ,{\cf22 'graduate'} \par
00003 , {\cf22 'graft'},{\cf22 'grant'}, {\cf22 'granulate'},{\cf22 'grasp'},{\cf22 'grate'},{\cf22 'gravel'},{\cf22 'gravitate'},{\cf22 'graze'},{\cf22 'grease'},{\cf22 'greet'},{\cf22 'grill'},{\cf22 'grin'},{\cf22 'grind'}, {\cf22 'grip'}, {\cf22 'groan'},{\cf22 'groom'},{\cf22 'grope'},{\cf22 'grow'},{\cf22 'growl'},{\cf22 'grub'},{\cf22 'grumble'},{\cf22 'grunt'},{\cf22 'guarantee'},{\cf22 'guard'},{\cf22 'guess'},{\cf22 'guide'}, {\cf22 'gurgle'} ,{\cf22 'gush'} ,{\cf22 'gut'} ,{\cf22 'guzzle'} \par
00004 ]\par
}
{
Definition at line {\b 13} of file {\b lexical.py}.}\par
}
\par \pard\plain 

\pard\plain \sect\sbkpage
\s2\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs28\kerning28\cgrid 
\pard\plain \s2\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs28\kerning28\cgrid 
main Namespace Reference\par \pard\plain 
{\tc\tcl2 \v main}
{\xe \v main}
{\bkmkstart AAAAAAAABA}
{\bkmkend AAAAAAAABA}
\pard\plain \s3\sb240\sa60\keepn\widctlpar\adjustright \b\f1\cgrid 
Classes\par
\pard\plain 

{
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
class {\b statement_tokenizer}\par
}
\par \pard\plain 

\pard\plain \sect\sbkpage
\s2\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs28\kerning28\cgrid 
\pard\plain \s2\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs28\kerning28\cgrid 
parts_speech Namespace Reference\par \pard\plain 
{\tc\tcl2 \v parts_speech}
{\xe \v parts_speech}
{\bkmkstart AAAAAAAABU}
{\bkmkend AAAAAAAABU}
\pard\plain \s3\sb240\sa60\keepn\widctlpar\adjustright \b\f1\cgrid 
Variables\par
\pard\plain 

{
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
list {\b nouns}\par
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
list {\b verbs}\par
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
list {\b adjectives}\par
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
list {\b adverbs}\par
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
list {\b conjunctions}\par
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
list {\b interjections}\par
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
list {\b pronouns}\par
}
{\pard\widctlpar\brdrb\brdrs\brdrw5\brsp20 \adjustright \par}
\pard\plain \s3\sb240\sa60\keepn\widctlpar\adjustright \b\f1\cgrid 
Variable Documentation\par
\pard\plain 
{\xe \v adjectives\:parts_speech}
{\xe \v parts_speech\:adjectives}
\pard\plain \s4\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs20\cgrid {
{\b 
list parts_speech.adjectives}}
\par
{\bkmkstart AAAAAAAABV}
{\bkmkend AAAAAAAABV}
{
\pard\plain \s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid 
{\b Initial value:}{
\pard\plain \s41\li360\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid 00001 =  [\par
00002     {\cf22 "bad"}, {\cf22 "backup"}, {\cf22 "bacteria"}, {\cf22 "baffling"}, {\cf22 "balanced"}, {\cf22 "ballsy"}, {\cf22 "balmy"}, {\cf22 "balsamic"}, {\cf22 "banging"}, {\cf22 "baronial"}, {\cf22 "bashful"}, {\cf22 "beady"}, {\cf22 "beaming"}, {\cf22 "bearing"}, {\cf22 "beatific"},\par
00003     {\cf22 "beautified"}, {\cf22 "beautifu"}, {\cf22 "beefy"}, {\cf22 "beguiling"}, {\cf22 "beginning"}, {\cf22 "bejeweled"}, {\cf22 "believable"}, {\cf22 "belligerent"}, {\cf22 "bell-like"}, {\cf22 "beloved"}, {\cf22 "benedictory"}, {\cf22 "benefic"}, {\cf22 "beneficent"},\par
00004     {\cf22 "beneficiary"}, {\cf22 "benevolent"}, {\cf22 "benign"}, {\cf22 "benignant"}, {\cf22 "bent"}, {\cf22 "best"}, {\cf22 "better"}, {\cf22 "bewitching"}, {\cf22 "becameral"}, {\cf22 "big"}, {\cf22 "biggest"}, {\cf22 "big-hearted"}, {\cf22 "big-time"}, {\cf22 "bijou"},\par
00005     {\cf22 "blameless"}, {\cf22 "blazing"}, {\cf22 "blessed"}, {\cf22 "blest"}, {\cf22 "blissful"}, {\cf22 "blistering"}, {\cf22 "blithe"}, {\cf22 "blooming"}, {\cf22 "blue-ribbon"}, {\cf22 "blushing"}, {\cf22 "bodacious"}, {\cf22 "boisterous"}, {\cf22 "bold"}, {\cf22 "bomb"},\par
00006     {\cf22 "bombastic"}, {\cf22 "bonkers"}, {\cf22 "bonny"}, {\cf22 "bonzer"}, {\cf22 "bookish"}, {\cf22 "boon"}, {\cf22 "bootylicious"}, {\cf22 "bosom"}, {\cf22 "botanical"}, {\cf22 "bouncy"}, {\cf22 "bound"}, {\cf22 "boundless"}, {\cf22 "bounteous"}, {\cf22 "bountiful"}, {\cf22 "bovine"},\par
00007     {\cf22 "bracing"}, {\cf22 "brackish"}, {\cf22 "brainy"}, {\cf22 "brash"}, {\cf22 "brave"}, {\cf22 "brawny"}, {\cf22 "brazen"}, {\cf22 "breathtaking"}, {\cf22 "breezy"}, {\cf22 "brief"}, {\cf22 "bright"}, {\cf22 "brill"}, {\cf22 "brilliant"}, {\cf22 "brimming"}, {\cf22 "brisk"},\par
00008 ]\par
}
{
Definition at line {\b 20} of file {\b parts_speech.py}.}\par
}
{\xe \v adverbs\:parts_speech}
{\xe \v parts_speech\:adverbs}
\pard\plain \s4\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs20\cgrid {
{\b 
list parts_speech.adverbs}}
\par
{\bkmkstart AAAAAAAABW}
{\bkmkend AAAAAAAABW}
{
\pard\plain \s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid 
{\b Initial value:}{
\pard\plain \s41\li360\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid 00001 =  [\par
00002     {\cf22 "badly"}, {\cf22 "back"}, {\cf22 "backstage"}, {\cf22 "backward"}, {\cf22 "badly"}, {\cf22 "barely"}, {\cf22 "basically"}, {\cf22 "beautifully"}, {\cf22 "beforehand"}, {\cf22 "begrudgingly"}, {\cf22 "behaviorally"}, {\cf22 "balatedly"}, {\cf22 "beliievably"},\par
00003     {\cf22 "below"}, {\cf22 "beneficlly"}, {\cf22 "bi-monthly"}, {\cf22 "biblically"}, {\cf22 "biennially"}, {\cf22 "bilaterally"}, {\cf22 "bimonthly"}, {\cf22 "biologically"}, {\cf22 "bit"}, {\cf22 "bitterly"}, {\cf22 "biweekly"}, {\cf22 "bizarrely"}, {\cf22 "blandly"},\par
00004     {\cf22 "blanky"}, {\cf22 "blatanly"}, {\cf22 "blazingly"}, {\cf22 "blessedly"}, {\cf22 "blindingly"}, {\cf22 "blindly"}, {\cf22 "blissfully"}, {\cf22 "blisteringly"}, {\cf22 "blithely"}, {\cf22 "bluntly"}, {\cf22 "boldly"}, {\cf22 "boringly"}, {\cf22 "botanically"},\par
00005     {\cf22 "bravely"}, {\cf22 "brazenly"}, {\cf22 "breathlessly"}, {\cf22 "breathtakingly"}, {\cf22 "briefly"}, {\cf22 "brightly"}, {\cf22 "brilliantly"}, {\cf22 "briskly"}, {\cf22 "broadly"}, {\cf22 "brutally"}, {\cf22 "busily"}, {\cf22 "braggingly"}, {\cf22 "bragly"}, {\cf22 "brashly"},\par
00006 ],\par
}
{
Definition at line {\b 30} of file {\b parts_speech.py}.}\par
}
{\xe \v conjunctions\:parts_speech}
{\xe \v parts_speech\:conjunctions}
\pard\plain \s4\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs20\cgrid {
{\b 
list parts_speech.conjunctions}}
\par
{\bkmkstart AAAAAAAABX}
{\bkmkend AAAAAAAABX}
{
\pard\plain \s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid 
{\b Initial value:}{
\pard\plain \s41\li360\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid 00001 =  [\par
00002     {\cf22 "because"}, {\cf22 "before"}, {\cf22 "behind"}, {\cf22 "below"}, {\cf22 "beneath"}, {\cf22 "beside"}, {\cf22 "between"}, {\cf22 "beyond"}, {\cf22 "but"}, {\cf22 "by"}, {\cf22 "by means of"}, {\cf22 "by virtue of"}, {\cf22 "by way of"}, {\cf22 "by virtue of"}, {\cf22 "by way of"}]\par
}
{
Definition at line {\b 38} of file {\b parts_speech.py}.}\par
}
{\xe \v interjections\:parts_speech}
{\xe \v parts_speech\:interjections}
\pard\plain \s4\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs20\cgrid {
{\b 
list parts_speech.interjections}}
\par
{\bkmkstart AAAAAAAABY}
{\bkmkend AAAAAAAABY}
{
\pard\plain \s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid 
{\b Initial value:}{
\pard\plain \s41\li360\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid 00001 =  [\par
00002     {\cf22 "bah"}, {\cf22 "bam"}, {\cf22 "bang"}, {\cf22 "barf"}, {\cf22 "bark"}, {\cf22 "bawl"}, {\cf22 "beep"}, {\cf22 "behold"}, {\cf22 "bellow"}, {\cf22 "bend"}, {\cf22 "beware"}]\par
}
{
Definition at line {\b 42} of file {\b parts_speech.py}.}\par
}
{\xe \v nouns\:parts_speech}
{\xe \v parts_speech\:nouns}
\pard\plain \s4\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs20\cgrid {
{\b 
list parts_speech.nouns}}
\par
{\bkmkstart AAAAAAAABZ}
{\bkmkend AAAAAAAABZ}
{
\pard\plain \s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid 
{\b Initial value:}{
\pard\plain \s41\li360\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid 00001 =  [\par
00002     {\cf22 "bachelor"}, {\cf22 "backbone"}, {\cf22 "balance"}, {\cf22 "brightness"}, {\cf22 "benefit"}, {\cf22 "being"}, {\cf22 "best"}, {\cf22 "booster"}, {\cf22 "bachelor"}, {\cf22 "babe"}, {\cf22 "black"}, {\cf22 "board"},\par
00003     {\cf22 "boarder"}, {\cf22 "broker"}, {\cf22 "bestseller"}, {\cf22 "beverage"}, {\cf22 "bean"}, {\cf22 "bail"}, {\cf22 "beast"}, {\cf22 "batch"}, {\cf22 "behind"}, {\cf22 "bracket"}, {\cf22 "brace"}, {\cf22 "builder"}, {\cf22 "beefalo"},\par
00004     {\cf22 "beef"}, {\cf22 "battery"}, {\cf22 "barn"}, {\cf22 "bone"}, {\cf22 "back"}, {\cf22 "butter"}, {\cf22 "bread"}, {\cf22 "beeper"}, {\cf22 "bowels"}, {\cf22 "bacon"}, {\cf22 "blaze"}, {\cf22 "blowup"}, {\cf22 "blackener"}, {\cf22 "blackhead"},\par
00005     {\cf22 "brisket"}, {\cf22 "barberry"}, {\cf22 "blueberries"}, {\cf22 "bus stop"}, {\cf22 "brow"}, {\cf22 "bale"}, {\cf22 "birthplace"}, {\cf22 "berlin"}, {\cf22 "bubbles"}, {\cf22 "buffer"}, {\cf22 "bucket"}, {\cf22 "bleachers"},\par
00006     {\cf22 "bike"}, {\cf22 "book"}, {\cf22 "bar"}, {\cf22 "breeze"}, {\cf22 "best"}, {\cf22 "backing"}, {\cf22 "block"}, {\cf22 "blackpool"}, {\cf22 "border"}, {\cf22 "bracelet"}, {\cf22 "bobbery"}, {\cf22 "bunkup"}, {\cf22 "band"}, {\cf22 "bucking"},\par
00007     {\cf22 "bag"}, {\cf22 "bootes"}, {\cf22 "bowtie"}, {\cf22 "bridle"}, {\cf22 "bettery"}, {\cf22 "backhoe"}, {\cf22 "bluebill"}, {\cf22 "barnacle"}, {\cf22 "bongo"}, {\cf22 "beef"}, {\cf22 "bicycle"}, {\cf22 "bulldog"}, {\cf22 "bluebill"},\par
00008 ]\par
}
{
Definition at line {\b 2} of file {\b parts_speech.py}.}\par
}
{\xe \v pronouns\:parts_speech}
{\xe \v parts_speech\:pronouns}
\pard\plain \s4\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs20\cgrid {
{\b 
list parts_speech.pronouns}}
\par
{\bkmkstart AAAAAAAACA}
{\bkmkend AAAAAAAACA}
{
\pard\plain \s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid 
{\b Initial value:}{
\pard\plain \s41\li360\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid 00001 =  [\par
00002     {\cf22 "both"}, {\cf22 "but"}, {\cf22 "by"}, {\cf22 "by means of"}, {\cf22 "by virtue of"}, {\cf22 "by way of"}, {\cf22 "by virtue of"}, {\cf22 "by way of"}]\par
}
{
Definition at line {\b 45} of file {\b parts_speech.py}.}\par
}
{\xe \v verbs\:parts_speech}
{\xe \v parts_speech\:verbs}
\pard\plain \s4\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs20\cgrid {
{\b 
list parts_speech.verbs}}
\par
{\bkmkstart AAAAAAAACB}
{\bkmkend AAAAAAAACB}
{
\pard\plain \s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid 
{\b Initial value:}{
\pard\plain \s41\li360\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid 00001 =  [\par
00002     {\cf22 "bake"}, {\cf22 "bark"}, {\cf22 "back"}, {\cf22 "backfire"}, {\cf22 "balance"}, {\cf22 "band"}, {\cf22 "bank"}, {\cf22 "baptize"}, {\cf22 "bar"}, {\cf22 "bargain"}, {\cf22 "bark"}, {\cf22 "barrack"}, {\cf22 "barter"}, {\cf22 "base"}, {\cf22 "bash"}, {\cf22 "bask"},\par
00003     {\cf22 "baste"}, {\cf22 "bat"}, {\cf22 "barrow"}, {\cf22 "bash"}, {\cf22 "bathe"}, {\cf22 "battle"}, {\cf22 "bawl"}, {\cf22 "be"}, {\cf22 "beach"}, {\cf22 "bear"}, {\cf22 "beat"}, {\cf22 "beath"}, {\cf22 "beatify"}, {\cf22 "beblood"}, {\cf22 "bebleed"}, {\cf22 "beblot"}, {\cf22 "beclap"},\par
00004     {\cf22 "becurl"}, {\cf22 "bedas"}, {\cf22 "bedribble"}, {\cf22 "bedrop"}, {\cf22 "bedrug"}, {\cf22 "beduck"}, {\cf22 "been"}, {\cf22 "bedflatter"}, {\cf22 "bedflower"}, {\cf22 "befrill"}, {\cf22 "beg"}, {\cf22 "begin"}, {\cf22 "begird"}, {\cf22 "beg"},\par
00005     {\cf22 "behead"}, {\cf22 "behoof"}, {\cf22 "being"}, {\cf22 "bejumble"}, {\cf22 "belate"}, {\cf22 "belk"}, {\cf22 "belong"}, {\cf22 "belt"}, {\cf22 "bemeet"}, {\cf22 "bemoil"}, {\cf22 "bemuse"}, {\cf22 "bename"}, {\cf22 "bend"}, {\cf22 "benefits"}, {\cf22 "bench"},\par
00006     {\cf22 "beray"}, {\cf22 "bereave"}, {\cf22 "berime"}, {\cf22 "bescreen"}, {\cf22 "beseek"}, {\cf22 "beshroud"}, {\cf22 "besit"}, {\cf22 "beslave"}, {\cf22 "beslime"}, {\cf22 "besnow"}, {\cf22 "besort"}, {\cf22 "bespice"}, {\cf22 "best"}, {\cf22 "bestain"},\par
00007     {\cf22 "betake"}, {\cf22 "betitle"}, {\cf22 "bethrall"}, {\cf22 "betoss"}, {\cf22 "betrap"}, {\cf22 "better"}, {\cf22 "bevel"}, {\cf22 "beware"}, {\cf22 "bewitch"}, {\cf22 "bewrap"}, {\cf22 "bicycle"}, {\cf22 "bike"}, {\cf22 "bill"}, {\cf22 "bind"}, {\cf22 "birth"}]\par
}
{
Definition at line {\b 12} of file {\b parts_speech.py}.}\par
}
\par \pard\plain 

\pard\plain \sect\sbkpage
\s2\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs28\kerning28\cgrid 
\pard\plain \s2\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs28\kerning28\cgrid 
statement Namespace Reference\par \pard\plain 
{\tc\tcl2 \v statement}
{\xe \v statement}
{\bkmkstart AAAAAAAACC}
{\bkmkend AAAAAAAACC}
\pard\plain \s3\sb240\sa60\keepn\widctlpar\adjustright \b\f1\cgrid 
Classes\par
\pard\plain 

{
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
class {\b statement_tokenizer}\par
}

\pard\plain \sect\sbkpage
\s1\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs36\kerning36\cgrid 
Class Documentation{\tc \v Class Documentation}
\par \pard\plain 
\pard\plain \s2\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs28\kerning28\cgrid 
main.statement_tokenizer Class Reference\par \pard\plain 
{\tc\tcl2 \v main.statement_tokenizer}
{\xe \v main.statement_tokenizer}
{\bkmkstart AAAAAAAABB}
{\bkmkend AAAAAAAABB}
\pard\plain \s3\sb240\sa60\keepn\widctlpar\adjustright \b\f1\cgrid 
Public Member Functions\par
\pard\plain 

{
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
def {\b __init__} (self)\par
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
list {\b get_tokens} (self, text)\par
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
str {\b __str__} (self)\par
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
str {\b __repr__} (self)\par
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
def {\b peformSentenceSplit} (self, text)\par
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
def {\b performWordSplit} (self, text)\par
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
def {\b getAllTokens} (self, text)\par
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
def {\b retainAllTokens} (self, text)\par
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
def {\b matchAllWordsStartingWithB} (self, text)\par
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
def {\b identifyPartsOfSpeech} (self, text)\par
}
\pard\plain \s3\sb240\sa60\keepn\widctlpar\adjustright \b\f1\cgrid 
Public Attributes\par
\pard\plain 

{
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
{\b nounList}\par
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
{\b pronounList}\par
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
{\b adjectiveList}\par
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
{\b verbList}\par
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
{\b adverbList}\par
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
{\b conjunctionsList}\par
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
{\b interjectionsList}\par
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
{\b unknownList}\par
}
{\pard\widctlpar\brdrb\brdrs\brdrw5\brsp20 \adjustright \par}
\pard\plain \s3\sb240\sa60\keepn\widctlpar\adjustright \b\f1\cgrid 
Detailed Description\par
\pard\plain 
{
\pard\plain \s17\sa60\sb30\widctlpar\qj \fs22\cgrid {
Definition at line {\b 7} of file {\b main.py}.}\par
}
{\pard\widctlpar\brdrb\brdrs\brdrw5\brsp20 \adjustright \par}
\pard\plain \s3\sb240\sa60\keepn\widctlpar\adjustright \b\f1\cgrid 
Constructor & Destructor Documentation\par
\pard\plain 
{\xe \v __init__\:main.statement_tokenizer}
{\xe \v main.statement_tokenizer\:__init__}
\pard\plain \s4\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs20\cgrid {
{\b 
def main.statement_tokenizer.__init__ (  {\i self})}}
\par
{\bkmkstart AAAAAAAABC}
{\bkmkend AAAAAAAABC}
{
\pard\plain \s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid 
{\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
{
\par
\pard\plain \s41\li360\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid This method is the constructor. where all the regex are defined and the word that the user or the calling file will use to call the method.}
 \par
}{
Definition at line {\b 8} of file {\b main.py}.}\par
}
{\pard\widctlpar\brdrb\brdrs\brdrw5\brsp20 \adjustright \par}
\pard\plain \s3\sb240\sa60\keepn\widctlpar\adjustright \b\f1\cgrid 
Member Function Documentation\par
\pard\plain 
{\xe \v __repr__\:main.statement_tokenizer}
{\xe \v main.statement_tokenizer\:__repr__}
\pard\plain \s4\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs20\cgrid {
{\b 
 str main.statement_tokenizer.__repr__ (  {\i self})}}
\par
{\bkmkstart AAAAAAAABD}
{\bkmkend AAAAAAAABD}
{
\pard\plain \s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid 
{\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
{
\par
\pard\plain \s41\li360\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid This method is responsible for the printing of the tokens that are returned by the get_tokens method.\par
it takes no arguments and returns a string of the tokens. it basically overites the default __repr__ method.}
 \par
}{
Definition at line {\b 40} of file {\b main.py}.}\par
}
{\xe \v __str__\:main.statement_tokenizer}
{\xe \v main.statement_tokenizer\:__str__}
\pard\plain \s4\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs20\cgrid {
{\b 
 str main.statement_tokenizer.__str__ (  {\i self})}}
\par
{\bkmkstart AAAAAAAABE}
{\bkmkend AAAAAAAABE}
{
\pard\plain \s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid 
{\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
{
\par
\pard\plain \s41\li360\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid This method is responsible for the printing of the tokens that are returned by the get_tokens method.\par
it takes no arguments and returns a string of the tokens. it basically overites the default __str__ method.}
 \par
}{
Definition at line {\b 33} of file {\b main.py}.}\par
}
{\xe \v get_tokens\:main.statement_tokenizer}
{\xe \v main.statement_tokenizer\:get_tokens}
\pard\plain \s4\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs20\cgrid {
{\b 
 list main.statement_tokenizer.get_tokens (  {\i self},   {\i text})}}
\par
{\bkmkstart AAAAAAAABF}
{\bkmkend AAAAAAAABF}
{
\pard\plain \s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid 
{\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
{
\par
\pard\plain \s41\li360\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid This method is responsible for the splitting of the individual strings into the required tokens which\par
takes  text (string) the text that is to be split into tokens. and returns a list of tokens.}
 \par
}{
Definition at line {\b 26} of file {\b main.py}.}\par
}
{\xe \v getAllTokens\:main.statement_tokenizer}
{\xe \v main.statement_tokenizer\:getAllTokens}
\pard\plain \s4\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs20\cgrid {
{\b 
def main.statement_tokenizer.getAllTokens (  {\i self},   {\i text})}}
\par
{\bkmkstart AAAAAAAABG}
{\bkmkend AAAAAAAABG}
{
\pard\plain \s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid 
{\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
{
\par
\pard\plain \s41\li360\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid This function is responsible for the tokenization of the whole text block. it takes the text block as an argument and returns a list of tokens.\par
}
 \par
}{
Definition at line {\b 63} of file {\b main.py}.}\par
}
{\xe \v identifyPartsOfSpeech\:main.statement_tokenizer}
{\xe \v main.statement_tokenizer\:identifyPartsOfSpeech}
\pard\plain \s4\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs20\cgrid {
{\b 
def main.statement_tokenizer.identifyPartsOfSpeech (  {\i self},   {\i text})}}
\par
{\bkmkstart AAAAAAAABH}
{\bkmkend AAAAAAAABH}
{
\pard\plain \s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid 
{\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
{
\par
\pard\plain \s41\li360\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid This function is responsible for the identification of the parts of speech of the words in the text block.\par
it takes the list of words as an argument and returns a list of parts of speech. This will make use of the [parts_speech] file\par
which contains the list of parts of speech and the words that belong to each part of speech. The group works on code that deals with the letter B\par
In cases where the\par
}
 \par
}{
Definition at line {\b 93} of file {\b main.py}.}\par
}
{\xe \v matchAllWordsStartingWithB\:main.statement_tokenizer}
{\xe \v main.statement_tokenizer\:matchAllWordsStartingWithB}
\pard\plain \s4\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs20\cgrid {
{\b 
def main.statement_tokenizer.matchAllWordsStartingWithB (  {\i self},   {\i text})}}
\par
{\bkmkstart AAAAAAAABI}
{\bkmkend AAAAAAAABI}
{
\pard\plain \s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid 
{\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
{
\par
\pard\plain \s41\li360\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid The aim of this function is to match all words starting with an A or a this is performed by the use of a regular expression}
 \par
}{
Definition at line {\b 87} of file {\b main.py}.}\par
}
{\xe \v peformSentenceSplit\:main.statement_tokenizer}
{\xe \v main.statement_tokenizer\:peformSentenceSplit}
\pard\plain \s4\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs20\cgrid {
{\b 
def main.statement_tokenizer.peformSentenceSplit (  {\i self},   {\i text})}}
\par
{\bkmkstart AAAAAAAABJ}
{\bkmkend AAAAAAAABJ}
{
\pard\plain \s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid 
{\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
{
\par
\pard\plain \s41\li360\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid This function takes part in tokenization of whole text blocks to aid the word tokenizer to be able to identifty tokens\par
based on specific word. This is a part which makes the whole system modular making it possible for the sentence to be handled as\par
blocks. this will also give the possibility to thet count of the number of sentences in\par
}
 \par
}{
Definition at line {\b 47} of file {\b main.py}.}\par
}
{\xe \v performWordSplit\:main.statement_tokenizer}
{\xe \v main.statement_tokenizer\:performWordSplit}
\pard\plain \s4\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs20\cgrid {
{\b 
def main.statement_tokenizer.performWordSplit (  {\i self},   {\i text})}}
\par
{\bkmkstart AAAAAAAABK}
{\bkmkend AAAAAAAABK}
{
\pard\plain \s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid 
{\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
{
\par
\pard\plain \s41\li360\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid This function takes part in tokenization of whole text blocks to aid the word tokenizer to be able to identifty tokens\par
based on specific word. This is a part which makes the whole system modular making it possible for the sentence to be handled as\par
blocks. this will also give the possibility to thet count of the number of sentences in\par
}
 \par
}{
Definition at line {\b 55} of file {\b main.py}.}\par
}
{\xe \v retainAllTokens\:main.statement_tokenizer}
{\xe \v main.statement_tokenizer\:retainAllTokens}
\pard\plain \s4\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs20\cgrid {
{\b 
def main.statement_tokenizer.retainAllTokens (  {\i self},   {\i text})}}
\par
{\bkmkstart AAAAAAAABL}
{\bkmkend AAAAAAAABL}
{
\pard\plain \s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid 
{\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
{
\par
\pard\plain \s41\li360\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid this fuction is tp prevent the elimination of special characters to avoid elimination during text splitting\par
this will be especially important what there will to be identification of known patters.\par
The function contains a special regular expresssion that checks all characaters individually\par
}
 \par
}{
Definition at line {\b 70} of file {\b main.py}.}\par
}
{\pard\widctlpar\brdrb\brdrs\brdrw5\brsp20 \adjustright \par}
\pard\plain \s3\sb240\sa60\keepn\widctlpar\adjustright \b\f1\cgrid 
Member Data Documentation\par
\pard\plain 
{\xe \v adjectiveList\:main.statement_tokenizer}
{\xe \v main.statement_tokenizer\:adjectiveList}
\pard\plain \s4\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs20\cgrid {
{\b 
main.statement_tokenizer.adjectiveList}}
\par
{\bkmkstart AAAAAAAABM}
{\bkmkend AAAAAAAABM}
{
\pard\plain \s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid 
\par
{
Definition at line {\b 18} of file {\b main.py}.}\par
}
{\xe \v adverbList\:main.statement_tokenizer}
{\xe \v main.statement_tokenizer\:adverbList}
\pard\plain \s4\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs20\cgrid {
{\b 
main.statement_tokenizer.adverbList}}
\par
{\bkmkstart AAAAAAAABN}
{\bkmkend AAAAAAAABN}
{
\pard\plain \s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid 
\par
{
Definition at line {\b 20} of file {\b main.py}.}\par
}
{\xe \v conjunctionsList\:main.statement_tokenizer}
{\xe \v main.statement_tokenizer\:conjunctionsList}
\pard\plain \s4\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs20\cgrid {
{\b 
main.statement_tokenizer.conjunctionsList}}
\par
{\bkmkstart AAAAAAAABO}
{\bkmkend AAAAAAAABO}
{
\pard\plain \s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid 
\par
{
Definition at line {\b 21} of file {\b main.py}.}\par
}
{\xe \v interjectionsList\:main.statement_tokenizer}
{\xe \v main.statement_tokenizer\:interjectionsList}
\pard\plain \s4\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs20\cgrid {
{\b 
main.statement_tokenizer.interjectionsList}}
\par
{\bkmkstart AAAAAAAABP}
{\bkmkend AAAAAAAABP}
{
\pard\plain \s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid 
\par
{
Definition at line {\b 22} of file {\b main.py}.}\par
}
{\xe \v nounList\:main.statement_tokenizer}
{\xe \v main.statement_tokenizer\:nounList}
\pard\plain \s4\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs20\cgrid {
{\b 
main.statement_tokenizer.nounList}}
\par
{\bkmkstart AAAAAAAABQ}
{\bkmkend AAAAAAAABQ}
{
\pard\plain \s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid 
\par
{
Definition at line {\b 16} of file {\b main.py}.}\par
}
{\xe \v pronounList\:main.statement_tokenizer}
{\xe \v main.statement_tokenizer\:pronounList}
\pard\plain \s4\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs20\cgrid {
{\b 
main.statement_tokenizer.pronounList}}
\par
{\bkmkstart AAAAAAAABR}
{\bkmkend AAAAAAAABR}
{
\pard\plain \s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid 
\par
{
Definition at line {\b 17} of file {\b main.py}.}\par
}
{\xe \v unknownList\:main.statement_tokenizer}
{\xe \v main.statement_tokenizer\:unknownList}
\pard\plain \s4\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs20\cgrid {
{\b 
main.statement_tokenizer.unknownList}}
\par
{\bkmkstart AAAAAAAABS}
{\bkmkend AAAAAAAABS}
{
\pard\plain \s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid 
\par
{
Definition at line {\b 23} of file {\b main.py}.}\par
}
{\xe \v verbList\:main.statement_tokenizer}
{\xe \v main.statement_tokenizer\:verbList}
\pard\plain \s4\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs20\cgrid {
{\b 
main.statement_tokenizer.verbList}}
\par
{\bkmkstart AAAAAAAABT}
{\bkmkend AAAAAAAABT}
{
\pard\plain \s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid 
\par
{
Definition at line {\b 19} of file {\b main.py}.}\par
}
{\pard\widctlpar\brdrb\brdrs\brdrw5\brsp20 \adjustright \par}
The documentation for this class was generated from the following file:{\par
\pard\plain \s121\fi-360\li720\widctlpar\jclisttab\tx720{\*\pn \pnlvlbody\ilvl0\ls2\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
{\b main.py}\par
}\par \pard\plain 

\pard\plain \sect\sbkpage
\s2\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs28\kerning28\cgrid 
\pard\plain \s2\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs28\kerning28\cgrid 
statement.statement_tokenizer Class Reference\par \pard\plain 
{\tc\tcl2 \v statement.statement_tokenizer}
{\xe \v statement.statement_tokenizer}
{\bkmkstart AAAAAAAACD}
{\bkmkend AAAAAAAACD}
\pard\plain \s3\sb240\sa60\keepn\widctlpar\adjustright \b\f1\cgrid 
Public Member Functions\par
\pard\plain 

{
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
def {\b __init__} (self)\par
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
list {\b get_tokens} (self, text)\par
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
str {\b __str__} (self)\par
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
str {\b __repr__} (self)\par
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
def {\b peformSentenceSplit} (self, text)\par
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
def {\b performWordSplit} (self, text)\par
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
def {\b getAllTokens} (self, text)\par
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
def {\b retainAllTokens} (self, text)\par
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
def {\b matchAllWordsStartingWithA} (self, text)\par
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
def {\b fsa} (word)\par
}
{\pard\widctlpar\brdrb\brdrs\brdrw5\brsp20 \adjustright \par}
\pard\plain \s3\sb240\sa60\keepn\widctlpar\adjustright \b\f1\cgrid 
Detailed Description\par
\pard\plain 
{
\pard\plain \s17\sa60\sb30\widctlpar\qj \fs22\cgrid {
Definition at line {\b 6} of file {\b statement.py}.}\par
}
{\pard\widctlpar\brdrb\brdrs\brdrw5\brsp20 \adjustright \par}
\pard\plain \s3\sb240\sa60\keepn\widctlpar\adjustright \b\f1\cgrid 
Constructor & Destructor Documentation\par
\pard\plain 
{\xe \v __init__\:statement.statement_tokenizer}
{\xe \v statement.statement_tokenizer\:__init__}
\pard\plain \s4\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs20\cgrid {
{\b 
def statement.statement_tokenizer.__init__ (  {\i self})}}
\par
{\bkmkstart AAAAAAAACE}
{\bkmkend AAAAAAAACE}
{
\pard\plain \s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid 
{\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
{
\par
\pard\plain \s41\li360\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid This method is the constructor. where all the regex are defined and the word that the user or the calling file will use to call the method.}
 \par
}{
Definition at line {\b 7} of file {\b statement.py}.}\par
}
{\pard\widctlpar\brdrb\brdrs\brdrw5\brsp20 \adjustright \par}
\pard\plain \s3\sb240\sa60\keepn\widctlpar\adjustright \b\f1\cgrid 
Member Function Documentation\par
\pard\plain 
{\xe \v __repr__\:statement.statement_tokenizer}
{\xe \v statement.statement_tokenizer\:__repr__}
\pard\plain \s4\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs20\cgrid {
{\b 
 str statement.statement_tokenizer.__repr__ (  {\i self})}}
\par
{\bkmkstart AAAAAAAACF}
{\bkmkend AAAAAAAACF}
{
\pard\plain \s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid 
{\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
{
\par
\pard\plain \s41\li360\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid This method is responsible for the printing of the tokens that are returned by the get_tokens method.\par
it takes no arguments and returns a string of the tokens. it basically overites the default __repr__ method.}
 \par
}{
Definition at line {\b 30} of file {\b statement.py}.}\par
}
{\xe \v __str__\:statement.statement_tokenizer}
{\xe \v statement.statement_tokenizer\:__str__}
\pard\plain \s4\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs20\cgrid {
{\b 
 str statement.statement_tokenizer.__str__ (  {\i self})}}
\par
{\bkmkstart AAAAAAAACG}
{\bkmkend AAAAAAAACG}
{
\pard\plain \s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid 
{\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
{
\par
\pard\plain \s41\li360\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid This method is responsible for the printing of the tokens that are returned by the get_tokens method.\par
it takes no arguments and returns a string of the tokens. it basically overites the default __str__ method.}
 \par
}{
Definition at line {\b 23} of file {\b statement.py}.}\par
}
{\xe \v fsa\:statement.statement_tokenizer}
{\xe \v statement.statement_tokenizer\:fsa}
\pard\plain \s4\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs20\cgrid {
{\b 
def statement.statement_tokenizer.fsa (  {\i word})}}
\par
{\bkmkstart AAAAAAAACH}
{\bkmkend AAAAAAAACH}
{
\pard\plain \s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid 
\par
{
Definition at line {\b 81} of file {\b statement.py}.}\par
}
{\xe \v get_tokens\:statement.statement_tokenizer}
{\xe \v statement.statement_tokenizer\:get_tokens}
\pard\plain \s4\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs20\cgrid {
{\b 
 list statement.statement_tokenizer.get_tokens (  {\i self},   {\i text})}}
\par
{\bkmkstart AAAAAAAACI}
{\bkmkend AAAAAAAACI}
{
\pard\plain \s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid 
{\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
{
\par
\pard\plain \s41\li360\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid This method is responsible for the splitting of the individual strings into the required tokens which\par
takes  text (string) the text that is to be split into tokens. and returns a list of tokens.}
 \par
}{
Definition at line {\b 16} of file {\b statement.py}.}\par
}
{\xe \v getAllTokens\:statement.statement_tokenizer}
{\xe \v statement.statement_tokenizer\:getAllTokens}
\pard\plain \s4\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs20\cgrid {
{\b 
def statement.statement_tokenizer.getAllTokens (  {\i self},   {\i text})}}
\par
{\bkmkstart AAAAAAAACJ}
{\bkmkend AAAAAAAACJ}
{
\pard\plain \s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid 
{\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
{
\par
\pard\plain \s41\li360\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid This function is responsible for the tokenization of the whole text block. it takes the text block as an argument and returns a list of tokens.\par
}
 \par
}{
Definition at line {\b 53} of file {\b statement.py}.}\par
}
{\xe \v matchAllWordsStartingWithA\:statement.statement_tokenizer}
{\xe \v statement.statement_tokenizer\:matchAllWordsStartingWithA}
\pard\plain \s4\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs20\cgrid {
{\b 
def statement.statement_tokenizer.matchAllWordsStartingWithA (  {\i self},   {\i text})}}
\par
{\bkmkstart AAAAAAAACK}
{\bkmkend AAAAAAAACK}
{
\pard\plain \s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid 
{\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
{
\par
\pard\plain \s41\li360\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid The aim of this function is to match all words starting with an A or a this is performed by the use of a regular expression}
 \par
}{
Definition at line {\b 77} of file {\b statement.py}.}\par
}
{\xe \v peformSentenceSplit\:statement.statement_tokenizer}
{\xe \v statement.statement_tokenizer\:peformSentenceSplit}
\pard\plain \s4\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs20\cgrid {
{\b 
def statement.statement_tokenizer.peformSentenceSplit (  {\i self},   {\i text})}}
\par
{\bkmkstart AAAAAAAACL}
{\bkmkend AAAAAAAACL}
{
\pard\plain \s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid 
{\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
{
\par
\pard\plain \s41\li360\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid This function takes part in tokenization of whole text blocks to aid the word tokenizer to be able to identifty tokens\par
based on specific word. This is a part which makes the whole system modular making it possible for the sentence to be handled as\par
blocks. this will also give the possibility to thet count of the number of sentences in\par
}
 \par
}{
Definition at line {\b 37} of file {\b statement.py}.}\par
}
{\xe \v performWordSplit\:statement.statement_tokenizer}
{\xe \v statement.statement_tokenizer\:performWordSplit}
\pard\plain \s4\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs20\cgrid {
{\b 
def statement.statement_tokenizer.performWordSplit (  {\i self},   {\i text})}}
\par
{\bkmkstart AAAAAAAACM}
{\bkmkend AAAAAAAACM}
{
\pard\plain \s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid 
{\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
{
\par
\pard\plain \s41\li360\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid This function takes part in tokenization of whole text blocks to aid the word tokenizer to be able to identifty tokens\par
based on specific word. This is a part which makes the whole system modular making it possible for the sentence to be handled as\par
blocks. this will also give the possibility to thet count of the number of sentences in\par
}
 \par
}{
Definition at line {\b 45} of file {\b statement.py}.}\par
}
{\xe \v retainAllTokens\:statement.statement_tokenizer}
{\xe \v statement.statement_tokenizer\:retainAllTokens}
\pard\plain \s4\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs20\cgrid {
{\b 
def statement.statement_tokenizer.retainAllTokens (  {\i self},   {\i text})}}
\par
{\bkmkstart AAAAAAAACN}
{\bkmkend AAAAAAAACN}
{
\pard\plain \s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid 
{\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
{
\par
\pard\plain \s41\li360\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid this fuction is tp prevent the elimination of special characters to avoid elimination during text splitting\par
this will be especially important what there will to be identification of known patters.\par
The function contains a special regular expresssion that checks all characaters individually\par
}
 \par
}{
Definition at line {\b 60} of file {\b statement.py}.}\par
}
{\pard\widctlpar\brdrb\brdrs\brdrw5\brsp20 \adjustright \par}
The documentation for this class was generated from the following file:{\par
\pard\plain \s121\fi-360\li720\widctlpar\jclisttab\tx720{\*\pn \pnlvlbody\ilvl0\ls2\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
{\b statement.py}\par
}
\pard\plain \sect\sbkpage
\s1\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs36\kerning36\cgrid 
File Documentation{\tc \v File Documentation}
\par \pard\plain 
\pard\plain \s2\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs28\kerning28\cgrid 
lexical.py File Reference\par \pard\plain 
{\tc\tcl2 \v lexical.py}
{\xe \v lexical.py}
{\bkmkstart AAAAAAAAAE}
{\bkmkend AAAAAAAAAE}
\pard\plain \s3\sb240\sa60\keepn\widctlpar\adjustright \b\f1\cgrid 
Namespaces\par
\pard\plain 

{
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
namespace {\b lexical}\par
}
\pard\plain \s3\sb240\sa60\keepn\widctlpar\adjustright \b\f1\cgrid 
Variables\par
\pard\plain 

{
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
string {\b lexical.text} = "Its show time"\par
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
list {\b lexical.punctuation} = ['!', '?',',','.',';',':']\par
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
list {\b lexical.noun} = ['+', '-', '*', '/', '=', '+=', '-=', '==', '<', '>', '<=', '>=']\par
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
list {\b lexical.adverb}\par
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
list {\b lexical.verb}\par
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
list {\b lexical.in_adverb} = []\par
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
list {\b lexical.in_spl_punctuation} = []\par
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
list {\b lexical.in_noun} = []\par
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
list {\b lexical.in_verb} = []\par
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
list {\b lexical.in_identifiers} = []\par
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
list {\b lexical.in_constants} = []\par
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
list {\b lexical.tokens} = []\par
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
bool {\b lexical.isStr} = False\par
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
bool {\b lexical.isWord} = False\par
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
int {\b lexical.isCmt} = 0\par
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
string {\b lexical.token} = ''\par
}
\par \pard\plain 

\pard\plain \sect\sbkpage
\s2\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs28\kerning28\cgrid 
\pard\plain \s2\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs28\kerning28\cgrid 
lexical.py\par \pard\plain 
{\bkmkstart AAAAAAAAAA}
{\bkmkend AAAAAAAAAA}
Go to the documentation of this file.{
\pard\plain \s40\li0\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid 00001 {\cf17 import} sys\par
00002 {\cf17 import} re\par
00003 \par
00004 \par
00005 text = {\cf22 "Its show time"}\par
00006 \par
00007 punctuation = [{\cf22 '!'}, {\cf22 '?'},{\cf22 ','},{\cf22 '.'},{\cf22 ';'},{\cf22 ':'}]\par
00008 noun = [{\cf22 '+'}, {\cf22 '-'}, {\cf22 '*'}, {\cf22 '/'}, {\cf22 '='}, {\cf22 '+='}, {\cf22 '-='}, {\cf22 '=='}, {\cf22 '<'}, {\cf22 '>'}, {\cf22 '<='}, {\cf22 '>='}]\par
00009 adverb = [{\cf22 'auto'},{\cf22 'break'}, {\cf22 'case'}, {\cf22 'char'}, {\cf22 'const'}, {\cf22 'continue'}, {\cf22 'default'}, {\cf22 'do'}, \par
00010             {\cf22 'double'}, {\cf22 'else'}, {\cf22 'enum'}, {\cf22 'extern'}, {\cf22 'float'}, {\cf22 'for'}, {\cf22 'goto'}, {\cf22 'if'}, \par
00011             {\cf22 'int'}, {\cf22 'long'}, {\cf22 'register'}, {\cf22 'return'}, {\cf22 'short'}, {\cf22 'signed'}, {\cf22 'sizeof'}, {\cf22 'static'}, \par
00012             {\cf22 'struct'}, {\cf22 'switch'}, {\cf22 'typedef'}, {\cf22 'union'}, {\cf22 'unsigned'}, {\cf22 'void'}, {\cf22 'volatile'}, {\cf22 'while'}]\par
00013 verb = [ {\cf22 'gag'} , {\cf22 'gain'} , {\cf22 'gallop'}, {\cf22 'gamble'} ,{\cf22 'gargle'} ,{\cf22 'garnish'} ,{\cf22 'gasp'} ,{\cf22 'gather'},{\cf22 'gauge'} ,{\cf22 'geld'} ,{\cf22 'generalize'} ,{\cf22 'generate'} , {\cf22 'germinate'} , {\cf22 'gesticulate'}, \par
00014  {\cf22 'get'} , {\cf22 'giggle'}, {\cf22 'gild'} ,{\cf22 'give'}, {\cf22 'glance'}, {\cf22 'glaze'} ,{\cf22 'gleam'} ,{\cf22 'glean'} ,{\cf22 'glide'} ,{\cf22 'glimmer'}, {\cf22 'glimpse'} ,{\cf22 'glisten'} ,{\cf22 'glitter'} ,{\cf22 'glorify'}, {\cf22 'gloss'} ,{\cf22 'glow'} ,{\cf22 'glue'} ,{\cf22 'gnash'} ,{\cf22 'gnaw'} ,{\cf22 'go'} ,{\cf22 'goad'}, {\cf22 'gossip'},  {\cf22 'govern'} ,{\cf22 'grab'} , {\cf22 'grace'} ,{\cf22 'grade'} ,{\cf22 'graduate'} \par
00015 , {\cf22 'graft'},{\cf22 'grant'}, {\cf22 'granulate'},{\cf22 'grasp'},{\cf22 'grate'},{\cf22 'gravel'},{\cf22 'gravitate'},{\cf22 'graze'},{\cf22 'grease'},{\cf22 'greet'},{\cf22 'grill'},{\cf22 'grin'},{\cf22 'grind'}, {\cf22 'grip'}, {\cf22 'groan'},{\cf22 'groom'},{\cf22 'grope'},{\cf22 'grow'},{\cf22 'growl'},{\cf22 'grub'},{\cf22 'grumble'},{\cf22 'grunt'},{\cf22 'guarantee'},{\cf22 'guard'},{\cf22 'guess'},{\cf22 'guide'}, {\cf22 'gurgle'} ,{\cf22 'gush'} ,{\cf22 'gut'} ,{\cf22 'guzzle'} \par
00016 ]\par
00017 \par
00018 \par
00019 in_adverb = []\par
00020 in_spl_punctuation = []\par
00021 in_noun = []\par
00022 in_verb = []\par
00023 in_identifiers = []\par
00024 in_constants = []\par
00025 \par
00026 tokens = []\par
00027 isStr = {\cf17 False}\par
00028 isWord = {\cf17 False}\par
00029 isCmt = 0\par
00030 token = {\cf22 ''}\par
00031 \par
00032 {\cf19 for} i {\cf19 in} text:\par
00033     {\cf19 if} i == {\cf22 '/'}:\par
00034         isCmt = isCmt+1\par
00035 \par
00036     {\cf19 elif} isCmt == 2:\par
00037         {\cf19 if} i == {\cf22 '\\n'}:\par
00038             token = {\cf22 ''}\par
00039             isCmt = 0\par
00040     \par
00041     {\cf19 elif} i == {\cf22 '"'} {\cf19 or} i == {\cf22 "'"}:\par
00042         {\cf19 if} isStr:\par
00043             tokens.append(token)\par
00044             token = {\cf22 ''}\par
00045         isStr = {\cf19 not} isStr \par
00046 \par
00047     {\cf19 elif} isStr:\par
00048         token = token+i\par
00049     \par
00050     {\cf19 elif} i {\cf19 in} punctuation:\par
00051         tokens.append(i)\par
00052            \par
00053     {\cf19 elif} i.isalnum() {\cf19 and} {\cf19 not} isWord:\par
00054         isWord = {\cf17 True}\par
00055         token = i\par
00056     \par
00057     {\cf19 elif} (i {\cf19 in} verb) {\cf19 or} (i {\cf19 in} noun):\par
00058         {\cf19 if} token:\par
00059             tokens.append(token)\par
00060             token = {\cf22 ''}\par
00061         \par
00062         {\cf19 if} {\cf19 not} (i=={\cf22 ' '} {\cf19 or} i=={\cf22 '\\n'} {\cf19 or} i=={\cf22 '   '}):\par
00063             tokens.append(i)\par
00064 \par
00065     {\cf19 elif} isWord:\par
00066         token = token+i\par
00067 \par
00068 \par
00069 {\cf19 for} token {\cf19 in} tokens:\par
00070     {\cf19 if} token {\cf19 in} punctuation:\par
00071         in_spl_punctuation.append(token)\par
00072 \par
00073     {\cf19 elif} token {\cf19 in} noun:\par
00074         in_noun.append(token)\par
00075 \par
00076     {\cf19 elif} token {\cf19 in} adverb:\par
00077         in_adverb.append(token)\par
00078                 \par
00079     {\cf19 elif} re.search({\cf22 "^[_a-zA-Z][_a-zA-Z0-9]*$"},token):\par
00080         in_identifiers.append(token)\par
00081         \par
00082     {\cf19 elif} token {\cf19 in} verb:\par
00083         in_verb.append(token)\par
00084         \par
00085     {\cf19 else}:\par
00086         in_constants.append(token)\par
00087     \par
00088                         \par
00089 print({\cf22 "No of tokens = "}, len(tokens))   \par
00090 print({\cf22 "\\nNo. of adverb = "},len(in_adverb))\par
00091 print(in_adverb);\par
00092 print({\cf22 "\\nNo. of special punctuation = "},len(in_spl_punctuation))\par
00093 print(in_spl_punctuation);\par
00094 print({\cf22 "\\nNo. of noun = "},len(in_noun))\par
00095 print(in_noun);\par
00096 print({\cf22 "\\nNo. of identifiers = "},len(in_identifiers))\par
00097 print(in_identifiers);\par
00098 print({\cf22 "\\nNo. of constants = "},len(in_constants))\par
00099 print(in_constants);\par
00100 print({\cf22 "\\nNo. of verb = "},len(in_verb))\par
00101 print(in_verb);\par
00102 f.close()   \par
}
\par \pard\plain 

\pard\plain \sect\sbkpage
\s2\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs28\kerning28\cgrid 
\pard\plain \s2\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs28\kerning28\cgrid 
main.py File Reference\par \pard\plain 
{\tc\tcl2 \v main.py}
{\xe \v main.py}
{\bkmkstart AAAAAAAAAF}
{\bkmkend AAAAAAAAAF}
\pard\plain \s3\sb240\sa60\keepn\widctlpar\adjustright \b\f1\cgrid 
Classes\par
\pard\plain 

{
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
class {\b main.statement_tokenizer}\par
}
\pard\plain \s3\sb240\sa60\keepn\widctlpar\adjustright \b\f1\cgrid 
Namespaces\par
\pard\plain 

{
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
namespace {\b main}\par
}
\par \pard\plain 

\pard\plain \sect\sbkpage
\s2\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs28\kerning28\cgrid 
\pard\plain \s2\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs28\kerning28\cgrid 
main.py\par \pard\plain 
{\bkmkstart AAAAAAAAAB}
{\bkmkend AAAAAAAAAB}
Go to the documentation of this file.{
\pard\plain \s40\li0\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid 00001 {\cf17 import} re\par
00002 {\cf17 from} parts_speech {\cf17 import} *\par
00003 \par
00004 {\cf22 """! @brief Example Python program with Doxygen style comments."""}\par
00005 \par
00006 \par
00007 {\cf17 class }statement_tokenizer:\par
00008     {\cf17 def }__init__(self):\par
00009         {\cf22 """}\par
00010 {\cf22         This method }{\cf19 is} the constructor. where all the regex are defined {\cf19 and} the word that the user {\cf19 or} the calling file will use to call the method.{\cf22 """}\par
00011 {\cf22         self._pattern = r"[A-Z]+[a-z]*\\s\\."}\par
00012         self._sentence_pattern = {\cf22 r'([A-Z][^\\.!?]*[\\.!?])'}\par
00013         self._word_pattern = {\cf22 r'\\w+'}\par
00014         self._regex = re.compile(self._sentence_pattern)\par
00015         self._tokens = []\par
00016         self.nounList = []\par
00017         self.pronounList = []\par
00018         self.adjectiveList = []\par
00019         self.verbList = []\par
00020         self.adverbList = []\par
00021         self.conjunctionsList = []\par
00022         self.interjectionsList = []\par
00023         self.unknownList = []\par
00024         self.adverbList = []\par
00025 \par
00026     {\cf17 def }get_tokens(self, text) -> list:\par
00027         {\cf22 """}\par
00028 {\cf22         This method }{\cf19 is} responsible {\cf19 for} the splitting of the individual strings into the required tokens which\par
00029         takes  text (string) the text that {\cf19 is} to be split into tokens. {\cf19 and} returns a list of tokens.{\cf22 """}\par
00030 {\cf22         self._tokens = self.peformSentenceSplit(text)}\par
00031 {\cf22         }{\cf19 return} self._tokens\par
00032 \par
00033     {\cf17 def }__str__(self) -> str:\par
00034         {\cf22 """}\par
00035 {\cf22         This method }{\cf19 is} responsible {\cf19 for} the printing of the tokens that are returned by the get_tokens method.\par
00036         it takes no arguments {\cf19 and} returns a string of the tokens. it basically overites the default __str__ method.{\cf22 """}\par
00037 {\cf22         }{\cf19 for} s {\cf19 in} self._tokens:\par
00038             print(f{\cf22 "statement -> \{s\}"})\par
00039 \par
00040     {\cf17 def }__repr__(self) -> str:\par
00041         {\cf22 """}\par
00042 {\cf22         This method }{\cf19 is} responsible {\cf19 for} the printing of the tokens that are returned by the get_tokens method.\par
00043         it takes no arguments {\cf19 and} returns a string of the tokens. it basically overites the default __repr__ method.{\cf22 """}\par
00044 {\cf22         }{\cf19 for} s {\cf19 in} self._tokens:\par
00045             print(f{\cf22 "statement -> \{s\}"})\par
00046 \par
00047     {\cf17 def }peformSentenceSplit(self, text):\par
00048         {\cf22 """This function takes part in tokenization of whole text blocks to aid the word tokenizer to be able to identifty tokens}\par
00049 {\cf22         based on specific word. This }{\cf19 is} a part which makes the whole system modular making it possible {\cf19 for} the sentence to be handled {\cf17 as}\par
00050         blocks. this will also give the possibility to thet count of the number of sentences {\cf19 in}\par
00051         {\cf22 """}\par
00052 {\cf22         formatter = re.compile(self._sentence_pattern, re.M)}\par
00053 {\cf22         }{\cf19 return} formatter.findall(text)\par
00054 \par
00055     {\cf17 def }performWordSplit(self, text):\par
00056         {\cf22 """This function takes part in tokenization of whole text blocks to aid the word tokenizer to be able to identifty tokens}\par
00057 {\cf22         based on specific word. This }{\cf19 is} a part which makes the whole system modular making it possible {\cf19 for} the sentence to be handled {\cf17 as}\par
00058         blocks. this will also give the possibility to thet count of the number of sentences {\cf19 in}\par
00059         {\cf22 """}\par
00060 {\cf22         formatter = re.compile(self._word_pattern, re.M)}\par
00061 {\cf22         }{\cf19 return} formatter.findall(text)\par
00062 \par
00063     {\cf17 def }getAllTokens(self, text):\par
00064         {\cf22 """}\par
00065 {\cf22         This function }{\cf19 is} responsible {\cf19 for} the tokenization of the whole text block. it takes the text block {\cf17 as} an argument {\cf19 and} returns a list of tokens.\par
00066         {\cf22 """}\par
00067 {\cf22         textData = self.retainAllTokens(text)}\par
00068 {\cf22         }{\cf19 return} textData.split()\par
00069 \par
00070     {\cf17 def }retainAllTokens(self, text):\par
00071         {\cf22 """}\par
00072 {\cf22         this fuction }{\cf19 is} tp prevent the elimination of special characters to avoid elimination during text splitting\par
00073         this will be especially important what there will to be identification of known patters.\par
00074         The function contains a special regular expresssion that checks all characaters individually\par
00075         {\cf22 """}\par
00076 {\cf22         new_text = ""}\par
00077         {\cf19 for} i {\cf19 in} range(len(text)):\par
00078             {\cf19 if} re.match({\cf22 r'\\.|,|\\?|\\'|\\)|\\\}|\\]|\\:|\\;'}, text[i]):\par
00079                 new_text = new_text+{\cf22 " "}+text[i]\par
00080             {\cf19 elif} re.match({\cf22 r'\\(|\\\{|\\[|\\s'}, text[i]):\par
00081                 new_text = new_text+text[i]+{\cf22 " "}\par
00082             {\cf19 else}:\par
00083                 new_text = new_text+text[i]\par
00084         {\cf19 return} new_text\par
00085 {\cf20 #    generate a dunction to match all words starting with an A or a}\par
00086 \par
00087     {\cf17 def }matchAllWordsStartingWithB(self, text):\par
00088         {\cf22 """The aim of this function is to match all words starting with an A or a this is performed by the use of a regular expression"""}\par
00089         formatter = re.compile({\cf22 r'\\b[Bb]\\w+'}, re.M)\par
00090         data = re.findall(formatter, text)\par
00091         print({\cf22 'Words starting with B or b are: '}, len(data))\par
00092         {\cf19 return} data\par
00093     {\cf17 def }identifyPartsOfSpeech(self, text):\par
00094         {\cf22 """This function is responsible for the identification of the parts of speech of the words in the text block.}\par
00095 {\cf22         it takes the list of words }{\cf17 as} an argument {\cf19 and} returns a list of parts of speech. This will make use of the [parts_speech] file\par
00096         which contains the list of parts of speech {\cf19 and} the words that belong to each part of speech. The group works on code that deals {\cf17 with} the letter B\par
00097         In cases where the\par
00098         {\cf22 """}\par
00099 {\cf22         data = self.matchAllWordsStartingWithB(text)}\par
00100 {\cf22         }{\cf19 for} word {\cf19 in} data:\par
00101             {\cf19 if} word {\cf19 in} nouns:\par
00102                 self.nounList.append(word)\par
00103             {\cf19 elif} word {\cf19 in} pronouns:\par
00104                 self.pronounList.append(word)\par
00105             {\cf19 elif} word {\cf19 in} adjectives:\par
00106                 self.adjectiveList.append(word)\par
00107             {\cf19 elif} word {\cf19 in} verbs:\par
00108                 self.verbList.append(word)\par
00109             {\cf19 elif} word {\cf19 in} adverbs:\par
00110                 self.adverbList.append(word)\par
00111             {\cf19 elif} word {\cf19 in} conjunctions:\par
00112                 self.conjunctionsList.append(word)\par
00113             {\cf19 elif} word {\cf19 in} interjections:\par
00114                 self.interjectionsList.append(word)\par
00115             {\cf19 else}:\par
00116                 self.unknownList.append(word+{\cf22 " Unknown"})\par
}
\par \pard\plain 

\pard\plain \sect\sbkpage
\s2\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs28\kerning28\cgrid 
\pard\plain \s2\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs28\kerning28\cgrid 
parts_speech.py File Reference\par \pard\plain 
{\tc\tcl2 \v parts_speech.py}
{\xe \v parts_speech.py}
{\bkmkstart AAAAAAAAAG}
{\bkmkend AAAAAAAAAG}
\pard\plain \s3\sb240\sa60\keepn\widctlpar\adjustright \b\f1\cgrid 
Namespaces\par
\pard\plain 

{
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
namespace {\b parts_speech}\par
}
\pard\plain \s3\sb240\sa60\keepn\widctlpar\adjustright \b\f1\cgrid 
Variables\par
\pard\plain 

{
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
list {\b parts_speech.nouns}\par
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
list {\b parts_speech.verbs}\par
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
list {\b parts_speech.adjectives}\par
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
list {\b parts_speech.adverbs}\par
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
list {\b parts_speech.conjunctions}\par
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
list {\b parts_speech.interjections}\par
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
list {\b parts_speech.pronouns}\par
}
\par \pard\plain 

\pard\plain \sect\sbkpage
\s2\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs28\kerning28\cgrid 
\pard\plain \s2\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs28\kerning28\cgrid 
parts_speech.py\par \pard\plain 
{\bkmkstart AAAAAAAAAC}
{\bkmkend AAAAAAAAAC}
Go to the documentation of this file.{
\pard\plain \s40\li0\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid 00001 {\cf20 # list of nouns starting with b}\par
00002 nouns = [\par
00003     {\cf22 "bachelor"}, {\cf22 "backbone"}, {\cf22 "balance"}, {\cf22 "brightness"}, {\cf22 "benefit"}, {\cf22 "being"}, {\cf22 "best"}, {\cf22 "booster"}, {\cf22 "bachelor"}, {\cf22 "babe"}, {\cf22 "black"}, {\cf22 "board"},\par
00004     {\cf22 "boarder"}, {\cf22 "broker"}, {\cf22 "bestseller"}, {\cf22 "beverage"}, {\cf22 "bean"}, {\cf22 "bail"}, {\cf22 "beast"}, {\cf22 "batch"}, {\cf22 "behind"}, {\cf22 "bracket"}, {\cf22 "brace"}, {\cf22 "builder"}, {\cf22 "beefalo"},\par
00005     {\cf22 "beef"}, {\cf22 "battery"}, {\cf22 "barn"}, {\cf22 "bone"}, {\cf22 "back"}, {\cf22 "butter"}, {\cf22 "bread"}, {\cf22 "beeper"}, {\cf22 "bowels"}, {\cf22 "bacon"}, {\cf22 "blaze"}, {\cf22 "blowup"}, {\cf22 "blackener"}, {\cf22 "blackhead"},\par
00006     {\cf22 "brisket"}, {\cf22 "barberry"}, {\cf22 "blueberries"}, {\cf22 "bus stop"}, {\cf22 "brow"}, {\cf22 "bale"}, {\cf22 "birthplace"}, {\cf22 "berlin"}, {\cf22 "bubbles"}, {\cf22 "buffer"}, {\cf22 "bucket"}, {\cf22 "bleachers"},\par
00007     {\cf22 "bike"}, {\cf22 "book"}, {\cf22 "bar"}, {\cf22 "breeze"}, {\cf22 "best"}, {\cf22 "backing"}, {\cf22 "block"}, {\cf22 "blackpool"}, {\cf22 "border"}, {\cf22 "bracelet"}, {\cf22 "bobbery"}, {\cf22 "bunkup"}, {\cf22 "band"}, {\cf22 "bucking"},\par
00008     {\cf22 "bag"}, {\cf22 "bootes"}, {\cf22 "bowtie"}, {\cf22 "bridle"}, {\cf22 "bettery"}, {\cf22 "backhoe"}, {\cf22 "bluebill"}, {\cf22 "barnacle"}, {\cf22 "bongo"}, {\cf22 "beef"}, {\cf22 "bicycle"}, {\cf22 "bulldog"}, {\cf22 "bluebill"},\par
00009 ]\par
00010 \par
00011 {\cf20 # list of verbs starting with the letter "b"}\par
00012 verbs = [\par
00013     {\cf22 "bake"}, {\cf22 "bark"}, {\cf22 "back"}, {\cf22 "backfire"}, {\cf22 "balance"}, {\cf22 "band"}, {\cf22 "bank"}, {\cf22 "baptize"}, {\cf22 "bar"}, {\cf22 "bargain"}, {\cf22 "bark"}, {\cf22 "barrack"}, {\cf22 "barter"}, {\cf22 "base"}, {\cf22 "bash"}, {\cf22 "bask"},\par
00014     {\cf22 "baste"}, {\cf22 "bat"}, {\cf22 "barrow"}, {\cf22 "bash"}, {\cf22 "bathe"}, {\cf22 "battle"}, {\cf22 "bawl"}, {\cf22 "be"}, {\cf22 "beach"}, {\cf22 "bear"}, {\cf22 "beat"}, {\cf22 "beath"}, {\cf22 "beatify"}, {\cf22 "beblood"}, {\cf22 "bebleed"}, {\cf22 "beblot"}, {\cf22 "beclap"},\par
00015     {\cf22 "becurl"}, {\cf22 "bedas"}, {\cf22 "bedribble"}, {\cf22 "bedrop"}, {\cf22 "bedrug"}, {\cf22 "beduck"}, {\cf22 "been"}, {\cf22 "bedflatter"}, {\cf22 "bedflower"}, {\cf22 "befrill"}, {\cf22 "beg"}, {\cf22 "begin"}, {\cf22 "begird"}, {\cf22 "beg"},\par
00016     {\cf22 "behead"}, {\cf22 "behoof"}, {\cf22 "being"}, {\cf22 "bejumble"}, {\cf22 "belate"}, {\cf22 "belk"}, {\cf22 "belong"}, {\cf22 "belt"}, {\cf22 "bemeet"}, {\cf22 "bemoil"}, {\cf22 "bemuse"}, {\cf22 "bename"}, {\cf22 "bend"}, {\cf22 "benefits"}, {\cf22 "bench"},\par
00017     {\cf22 "beray"}, {\cf22 "bereave"}, {\cf22 "berime"}, {\cf22 "bescreen"}, {\cf22 "beseek"}, {\cf22 "beshroud"}, {\cf22 "besit"}, {\cf22 "beslave"}, {\cf22 "beslime"}, {\cf22 "besnow"}, {\cf22 "besort"}, {\cf22 "bespice"}, {\cf22 "best"}, {\cf22 "bestain"},\par
00018     {\cf22 "betake"}, {\cf22 "betitle"}, {\cf22 "bethrall"}, {\cf22 "betoss"}, {\cf22 "betrap"}, {\cf22 "better"}, {\cf22 "bevel"}, {\cf22 "beware"}, {\cf22 "bewitch"}, {\cf22 "bewrap"}, {\cf22 "bicycle"}, {\cf22 "bike"}, {\cf22 "bill"}, {\cf22 "bind"}, {\cf22 "birth"}]\par
00019 {\cf20 # list of adjectives starting with the letter "b"}\par
00020 adjectives = [\par
00021     {\cf22 "bad"}, {\cf22 "backup"}, {\cf22 "bacteria"}, {\cf22 "baffling"}, {\cf22 "balanced"}, {\cf22 "ballsy"}, {\cf22 "balmy"}, {\cf22 "balsamic"}, {\cf22 "banging"}, {\cf22 "baronial"}, {\cf22 "bashful"}, {\cf22 "beady"}, {\cf22 "beaming"}, {\cf22 "bearing"}, {\cf22 "beatific"},\par
00022     {\cf22 "beautified"}, {\cf22 "beautifu"}, {\cf22 "beefy"}, {\cf22 "beguiling"}, {\cf22 "beginning"}, {\cf22 "bejeweled"}, {\cf22 "believable"}, {\cf22 "belligerent"}, {\cf22 "bell-like"}, {\cf22 "beloved"}, {\cf22 "benedictory"}, {\cf22 "benefic"}, {\cf22 "beneficent"},\par
00023     {\cf22 "beneficiary"}, {\cf22 "benevolent"}, {\cf22 "benign"}, {\cf22 "benignant"}, {\cf22 "bent"}, {\cf22 "best"}, {\cf22 "better"}, {\cf22 "bewitching"}, {\cf22 "becameral"}, {\cf22 "big"}, {\cf22 "biggest"}, {\cf22 "big-hearted"}, {\cf22 "big-time"}, {\cf22 "bijou"},\par
00024     {\cf22 "blameless"}, {\cf22 "blazing"}, {\cf22 "blessed"}, {\cf22 "blest"}, {\cf22 "blissful"}, {\cf22 "blistering"}, {\cf22 "blithe"}, {\cf22 "blooming"}, {\cf22 "blue-ribbon"}, {\cf22 "blushing"}, {\cf22 "bodacious"}, {\cf22 "boisterous"}, {\cf22 "bold"}, {\cf22 "bomb"},\par
00025     {\cf22 "bombastic"}, {\cf22 "bonkers"}, {\cf22 "bonny"}, {\cf22 "bonzer"}, {\cf22 "bookish"}, {\cf22 "boon"}, {\cf22 "bootylicious"}, {\cf22 "bosom"}, {\cf22 "botanical"}, {\cf22 "bouncy"}, {\cf22 "bound"}, {\cf22 "boundless"}, {\cf22 "bounteous"}, {\cf22 "bountiful"}, {\cf22 "bovine"},\par
00026     {\cf22 "bracing"}, {\cf22 "brackish"}, {\cf22 "brainy"}, {\cf22 "brash"}, {\cf22 "brave"}, {\cf22 "brawny"}, {\cf22 "brazen"}, {\cf22 "breathtaking"}, {\cf22 "breezy"}, {\cf22 "brief"}, {\cf22 "bright"}, {\cf22 "brill"}, {\cf22 "brilliant"}, {\cf22 "brimming"}, {\cf22 "brisk"},\par
00027 ]\par
00028 {\cf20 # list of adjectives starting with letter "b"}\par
00029 {\cf20 # list of adverbs starting with the letter "b"}\par
00030 adverbs = [\par
00031     {\cf22 "badly"}, {\cf22 "back"}, {\cf22 "backstage"}, {\cf22 "backward"}, {\cf22 "badly"}, {\cf22 "barely"}, {\cf22 "basically"}, {\cf22 "beautifully"}, {\cf22 "beforehand"}, {\cf22 "begrudgingly"}, {\cf22 "behaviorally"}, {\cf22 "balatedly"}, {\cf22 "beliievably"},\par
00032     {\cf22 "below"}, {\cf22 "beneficlly"}, {\cf22 "bi-monthly"}, {\cf22 "biblically"}, {\cf22 "biennially"}, {\cf22 "bilaterally"}, {\cf22 "bimonthly"}, {\cf22 "biologically"}, {\cf22 "bit"}, {\cf22 "bitterly"}, {\cf22 "biweekly"}, {\cf22 "bizarrely"}, {\cf22 "blandly"},\par
00033     {\cf22 "blanky"}, {\cf22 "blatanly"}, {\cf22 "blazingly"}, {\cf22 "blessedly"}, {\cf22 "blindingly"}, {\cf22 "blindly"}, {\cf22 "blissfully"}, {\cf22 "blisteringly"}, {\cf22 "blithely"}, {\cf22 "bluntly"}, {\cf22 "boldly"}, {\cf22 "boringly"}, {\cf22 "botanically"},\par
00034     {\cf22 "bravely"}, {\cf22 "brazenly"}, {\cf22 "breathlessly"}, {\cf22 "breathtakingly"}, {\cf22 "briefly"}, {\cf22 "brightly"}, {\cf22 "brilliantly"}, {\cf22 "briskly"}, {\cf22 "broadly"}, {\cf22 "brutally"}, {\cf22 "busily"}, {\cf22 "braggingly"}, {\cf22 "bragly"}, {\cf22 "brashly"},\par
00035 ],\par
00036 \par
00037 {\cf20 # conjunctions starting with the letter "b"}\par
00038 conjunctions = [\par
00039     {\cf22 "because"}, {\cf22 "before"}, {\cf22 "behind"}, {\cf22 "below"}, {\cf22 "beneath"}, {\cf22 "beside"}, {\cf22 "between"}, {\cf22 "beyond"}, {\cf22 "but"}, {\cf22 "by"}, {\cf22 "by means of"}, {\cf22 "by virtue of"}, {\cf22 "by way of"}, {\cf22 "by virtue of"}, {\cf22 "by way of"}]\par
00040 \par
00041 {\cf20 # list of intergecting conjunctions starting with the letter "b"}\par
00042 interjections = [\par
00043     {\cf22 "bah"}, {\cf22 "bam"}, {\cf22 "bang"}, {\cf22 "barf"}, {\cf22 "bark"}, {\cf22 "bawl"}, {\cf22 "beep"}, {\cf22 "behold"}, {\cf22 "bellow"}, {\cf22 "bend"}, {\cf22 "beware"}]\par
00044 {\cf20 # list of pronouns starting with the letter "b"}\par
00045 pronouns = [\par
00046     {\cf22 "both"}, {\cf22 "but"}, {\cf22 "by"}, {\cf22 "by means of"}, {\cf22 "by virtue of"}, {\cf22 "by way of"}, {\cf22 "by virtue of"}, {\cf22 "by way of"}]\par
}
\par \pard\plain 

\pard\plain \sect\sbkpage
\s2\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs28\kerning28\cgrid 
\pard\plain \s2\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs28\kerning28\cgrid 
README.md File Reference\par \pard\plain 
{\tc\tcl2 \v README.md}
{\xe \v README.md}
{\bkmkstart AAAAAAAAAH}
{\bkmkend AAAAAAAAAH}
\par \pard\plain 

\pard\plain \sect\sbkpage
\s2\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs28\kerning28\cgrid 
\pard\plain \s2\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs28\kerning28\cgrid 
statement.py File Reference\par \pard\plain 
{\tc\tcl2 \v statement.py}
{\xe \v statement.py}
{\bkmkstart AAAAAAAAAI}
{\bkmkend AAAAAAAAAI}
\pard\plain \s3\sb240\sa60\keepn\widctlpar\adjustright \b\f1\cgrid 
Classes\par
\pard\plain 

{
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
class {\b statement.statement_tokenizer}\par
}
\pard\plain \s3\sb240\sa60\keepn\widctlpar\adjustright \b\f1\cgrid 
Namespaces\par
\pard\plain 

{
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
namespace {\b statement}\par
}
\par \pard\plain 

\pard\plain \sect\sbkpage
\s2\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs28\kerning28\cgrid 
\pard\plain \s2\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs28\kerning28\cgrid 
statement.py\par \pard\plain 
{\bkmkstart AAAAAAAAAD}
{\bkmkend AAAAAAAAAD}
Go to the documentation of this file.{
\pard\plain \s40\li0\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid 00001 {\cf17 import} re\par
00002 \par
00003 {\cf22 """! @brief Example Python program with Doxygen style comments."""}\par
00004 \par
00005 \par
00006 {\cf17 class }statement_tokenizer:\par
00007     {\cf17 def }__init__(self):\par
00008         {\cf22 """}\par
00009 {\cf22         This method }{\cf19 is} the constructor. where all the regex are defined {\cf19 and} the word that the user {\cf19 or} the calling file will use to call the method.{\cf22 """}\par
00010 {\cf22         self._pattern = r"[A-Z]+[a-z]*\\s\\."}\par
00011         self._sentence_pattern = {\cf22 r'([A-Z][^\\.!?]*[\\.!?])'}\par
00012         self._word_pattern = {\cf22 r'\\w+'}\par
00013         self._regex = re.compile(self._sentence_pattern)\par
00014         self._tokens = []\par
00015 \par
00016     {\cf17 def }get_tokens(self, text) -> list:\par
00017         {\cf22 """}\par
00018 {\cf22         This method }{\cf19 is} responsible {\cf19 for} the splitting of the individual strings into the required tokens which\par
00019         takes  text (string) the text that {\cf19 is} to be split into tokens. {\cf19 and} returns a list of tokens.{\cf22 """}\par
00020 {\cf22         self._tokens = self.peformSentenceSplit(text)}\par
00021 {\cf22         }{\cf19 return} self._tokens\par
00022 \par
00023     {\cf17 def }__str__(self) -> str:\par
00024         {\cf22 """}\par
00025 {\cf22         This method }{\cf19 is} responsible {\cf19 for} the printing of the tokens that are returned by the get_tokens method.\par
00026         it takes no arguments {\cf19 and} returns a string of the tokens. it basically overites the default __str__ method.{\cf22 """}\par
00027 {\cf22         }{\cf19 for} s {\cf19 in} self._tokens:\par
00028             print(f{\cf22 "statement -> \{s\}"})\par
00029 \par
00030     {\cf17 def }__repr__(self) -> str:\par
00031         {\cf22 """}\par
00032 {\cf22         This method }{\cf19 is} responsible {\cf19 for} the printing of the tokens that are returned by the get_tokens method.\par
00033         it takes no arguments {\cf19 and} returns a string of the tokens. it basically overites the default __repr__ method.{\cf22 """}\par
00034 {\cf22         }{\cf19 for} s {\cf19 in} self._tokens:\par
00035             print(f{\cf22 "statement -> \{s\}"})\par
00036 \par
00037     {\cf17 def }peformSentenceSplit(self, text):\par
00038         {\cf22 """This function takes part in tokenization of whole text blocks to aid the word tokenizer to be able to identifty tokens}\par
00039 {\cf22         based on specific word. This }{\cf19 is} a part which makes the whole system modular making it possible {\cf19 for} the sentence to be handled {\cf17 as}\par
00040         blocks. this will also give the possibility to thet count of the number of sentences {\cf19 in}\par
00041         {\cf22 """}\par
00042 {\cf22         formatter = re.compile(self._sentence_pattern, re.M)}\par
00043 {\cf22         }{\cf19 return} formatter.findall(text)\par
00044 \par
00045     {\cf17 def }performWordSplit(self, text):\par
00046         {\cf22 """This function takes part in tokenization of whole text blocks to aid the word tokenizer to be able to identifty tokens}\par
00047 {\cf22         based on specific word. This }{\cf19 is} a part which makes the whole system modular making it possible {\cf19 for} the sentence to be handled {\cf17 as}\par
00048         blocks. this will also give the possibility to thet count of the number of sentences {\cf19 in}\par
00049         {\cf22 """}\par
00050 {\cf22         formatter = re.compile(self._word_pattern, re.M)}\par
00051 {\cf22         }{\cf19 return} formatter.findall(text)\par
00052 \par
00053     {\cf17 def }getAllTokens(self, text):\par
00054         {\cf22 """}\par
00055 {\cf22         This function }{\cf19 is} responsible {\cf19 for} the tokenization of the whole text block. it takes the text block {\cf17 as} an argument {\cf19 and} returns a list of tokens.\par
00056         {\cf22 """}\par
00057 {\cf22         textData = self.retainAllTokens(text)}\par
00058 {\cf22         }{\cf19 return} textData.split()\par
00059 \par
00060     {\cf17 def }retainAllTokens(self, text):\par
00061         {\cf22 """}\par
00062 {\cf22         this fuction }{\cf19 is} tp prevent the elimination of special characters to avoid elimination during text splitting\par
00063         this will be especially important what there will to be identification of known patters.\par
00064         The function contains a special regular expresssion that checks all characaters individually\par
00065         {\cf22 """}\par
00066 {\cf22         new_text = ""}\par
00067         {\cf19 for} i {\cf19 in} range(len(text)):\par
00068             {\cf19 if} re.match({\cf22 r'\\.|,|\\?|\\'|\\)|\\\}|\\]|\\:|\\;'}, text[i]):\par
00069                 new_text = new_text+{\cf22 " "}+text[i]\par
00070             {\cf19 elif} re.match({\cf22 r'\\(|\\\{|\\[|\\s'}, text[i]):\par
00071                 new_text = new_text+text[i]+{\cf22 " "}\par
00072             {\cf19 else}:\par
00073                 new_text = new_text+text[i]\par
00074         {\cf19 return} new_text\par
00075 {\cf20 #    generate a dunction to match all words starting with an A or a}\par
00076 \par
00077     {\cf17 def }matchAllWordsStartingWithA(self, text):\par
00078         {\cf22 """The aim of this function is to match all words starting with an A or a this is performed by the use of a regular expression"""}\par
00079         {\cf19 return} re.findall({\cf22 r'\\b[Aa]\\w+'}, text)\par
00080 \par
00081     {\cf17 def }fsa(word):\par
00082         if(re.search({\cf22 r'^a.+'}, word)):\par
00083             {\cf19 if} re.search({\cf22 r'.*ance$'}, word) {\cf19 or} re.search({\cf22 r'.*ence$'}, word) {\cf19 or} re.search({\cf22 r'.*ar$'}, word) {\cf19 or} re.search({\cf22 r'.*er$'}, word) {\cf19 or} re.search({\cf22 r'.*ir$'}, word) {\cf19 or} re.search({\cf22 r'.*or$'}, word) {\cf19 or} re.search({\cf22 r'.*ur$'}, word) {\cf19 or} re.search({\cf22 r'.*ism$'}, word) {\cf19 or} re.search({\cf22 r'.*ment$'}, word) {\cf19 or} re.search({\cf22 r'.*age$'}, word) {\cf19 or} re.search({\cf22 r'.*hood$'}, word) {\cf19 or} re.search({\cf22 r'.*ness$'}, word) {\cf19 or} re.search({\cf22 r'.*irt$'}, word) {\cf19 or} re.search({\cf22 r'.*er$'}, word) {\cf19 or} re.search({\cf22 r'.*bots'}, word):\par
00084                 {\cf19 return} {\cf22 "noun"}\par
00085             {\cf19 elif} re.search({\cf22 r'.*able$'}, word) {\cf19 or} re.search({\cf22 r'.*ible$'}, word) {\cf19 or} re.search({\cf22 r'.*ant$'}, word) {\cf19 or} re.search({\cf22 r'.*ent$'}, word) {\cf19 or} re.search({\cf22 r'.*ists$'}, word) {\cf19 or} re.search({\cf22 r'.*ist$'}, word) {\cf19 or} re.search({\cf22 r'.*ous$'}, word) {\cf19 or} re.search({\cf22 r'.*ful$'}, word) {\cf19 or} re.search({\cf22 r'.*ish'}, word) {\cf19 or} re.search({\cf22 r'.*ive$'}, word) {\cf19 or} re.search({\cf22 r'.*ize$'}, word) {\cf19 or} re.search({\cf22 r'.*ate$'}, word) {\cf19 or} re.search({\cf22 r'.*ify$'}, word) {\cf19 or} re.search({\cf22 r'.*ise$'}, word) {\cf19 or} re.search({\cf22 r'.*ate$'}, word) {\cf19 or} re.search({\cf22 r'.*ise$'}, word) {\cf19 or} re.search({\cf22 r'.*ate$'}, word) {\cf19 or} re.search({\cf22 r'.*ise$'}, word) {\cf19 or} re.search({\cf22 r'.*ate$'}, word) {\cf19 or} re.search({\cf22 r'.*ise$'}, word) {\cf19 or} re.search({\cf22 r'.*ize'}, word) {\cf19 or} re.search({\cf22 r'.*ate$'}, word) {\cf19 or} re.search({\cf22 r'.*ise$'}, word) {\cf19 or} re.search({\cf22 r'.*ize$'}, word) {\cf19 or} re.search({\cf22 r'.*ate$'}, word) {\cf19 or} re.search({\cf22 r'.*ise$'}, word) {\cf19 or} re.search({\cf22 r'.*ate$'}, word) {\cf19 or} re.search({\cf22 r'.*ise$'}, word) {\cf19 or} re.search({\cf22 r'.*ate$'}, word) {\cf19 or} re.search({\cf22 r'.*ise$'}, word) {\cf19 or} re.search({\cf22 r'.*ate$'}, word) {\cf19 or} re.search({\cf22 r'.*ise$'}, word) {\cf19 or} re.search({\cf22 r'.*ize$'}, word) {\cf19 or} re.search({\cf22 r'.*ate$'}, word) {\cf19 or} re.search({\cf22 r'.*ise$'}, word) {\cf19 or} re.search({\cf22 r'.*ize$'}, word) {\cf19 or} re.search({\cf22 r'.*ate$'}, word) {\cf19 or} re.search({\cf22 r'.*ise$'}, word) {\cf19 or} re.search({\cf22 r'.*ize$'}, word) {\cf19 or} re.search({\cf22 r'.*ed$'}, word) {\cf19 or} re.search({\cf22 r'.*ate$'}, word) {\cf19 or} re.search({\cf22 r'.*y$'}, word) {\cf19 or} re.search({\cf22 r'.*ons$'}, word) {\cf19 or} re.search({\cf22 r'.*ing'}, word) {\cf19 or} re.search({\cf22 r'.*de'}, word) {\cf19 or} re.search({\cf22 r'.*ound'}, word):\par
00086                 {\cf19 return} {\cf22 "verb"}\par
00087             {\cf19 elif} re.search({\cf22 r'.*ly$'}, word) {\cf19 or} re.search({\cf22 r'.*ry$'}, word) {\cf19 or} word == {\cf22 "right"} {\cf19 or} re.search({\cf22 r'.*here$'}, word) {\cf19 or} word == {\cf22 "wrong"} {\cf19 or} re.search({\cf22 r'.*here$'}, word) {\cf19 or} word == {\cf22 'soon'} {\cf19 or} re.search({\cf22 r'.*soon$'}, word) {\cf19 or} re.search({\cf22 r'.*times$'}, word) {\cf19 or} re.search({\cf22 r'.*in$'}, word):\par
00088                 {\cf19 return} {\cf22 "adverb"}\par
00089             {\cf19 else}:\par
00090                 {\cf19 return} {\cf22 "valid but unknown"}\par
00091         {\cf19 else}:\par
00092             {\cf19 return} {\cf22 "invalid word"}\par
00093     {\cf20 # generate a function to identify all parts of speech in a text}\par
00094     {\cf20 # def identifyAllPartsOfSpeech(self, text):}\par
00095 \par
00096 \par
00097 {\cf20 # if __name__ == "__main__":}\par
00098 {\cf20 #     data = statement_tokenizer()}\par
00099 {\cf20 #     text = """Today, technology is a subject of debate because it is considered to be a double-edged sword. While it has helped humanity in extending its potential with outstanding inventions, it is nonetheless threatening humankind through some other destructive ones. In addition to polluting the earth in unprecedented ways, wars have become more and more devastating due to technological inventions. Ethical dimensions of recent technological developments, such as DNA engineering, have become a focal point of questioning and discussion. Philosophical debates have arisen over the use of technology, with disagreements over whether technology improves the human condition or worsens it.}\par
00100 {\cf20 # To make matters worse, a consensus definition of technology has become more difficult to find due to recent evolution in science and its applications. It is especially confusing to decide whether technology refers to the machines (or more precisely the hardware), the rules that govern or make them work, the system that operates them or the different applications of science that are related to them. What is sure is that technology has shaped societies and adapted itself to people's changing needs.}\par
00101 {\cf20 # """}\par
00102 {\cf20 #     formatted = data.retainAllTokens(text.strip())}\par
00103 {\cf20 #     print(" ".join(data.matchAllWordsStartingWithA(formatted)))}\par
}

\pard\plain \sect\sbkpage
\s1\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs36\kerning36\cgrid 
\s1\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs36\kerning36\cgrid Index\par 
\pard\plain 
{\tc \v Index}
{\field\fldedit {\*\fldinst INDEX \\c2 \\*MERGEFORMAT}{\fldrslt INDEX}}
}
